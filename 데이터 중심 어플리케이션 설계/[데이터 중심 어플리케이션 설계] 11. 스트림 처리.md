배치 처리와도 동일하지만 모든 처리의 출력은 파생 데이터의 형태이다.

데이터는 한정되지 않고 계속 생상된다. 일괄 처리는 느리기에 좀 더 빠른 처리가 필요하게 되었다. 

> 스트림 처리는 고정된 시간 조각이라는 개념을 버리고 단순히 이벤트가 발생할 떄마다 처리한다.

## 이벤트 스트림 전송

입력은 바이트의 연속이지만, 스트림 처리는 이를 보통 이벤트라고 한다. 각 이벤트를 작고 독립된 불변 객체로써 데이터 처리를 진행한다.(이벤트 발생 타임스탬프 포함)

이러한 이벤트는 원본그대로가 아니라 JSON or BSON 형태로 부호화된다. 이벤트는 부호화 과정을 통해 저장되고 활용된다. 

>파일은 한 번 기록되면 여러 작업에서 활용할 수 있다. 보통 **프로듀서**가 이벤트를 한 번 만들면 복수의 **컨슈머**가 처리한다. 대게 데이터를 **토픽**단위로 묶는다.

이론상으로는 데이터베이스가 있으면 이 로직은 구현할 수 있다. 하지만 데이터베이스를 폴링하여 새로운 이벤트를 가져오는 것은 비용이 크다. 따라서 다른 방식이 사용되게 된다.

### 메시징 시스템

생산자는 이벤트를 포함한 메시지를 전송하고, 소비자는 이를 읽어 활용한다. 

메시징 시스템을 구축하는 가장 간단한 방법은 생산자와 소비자 사이에 유닉스 파이프나 TCP과 같은 직접 통신 채널을 사용하는 방법이다. (메시지 시스템은 보통 해당 모델을 확장하여 사용한다.)

#### 카프카의 프로듀서 및 컨슈머 그리고 브로커

![](https://velog.velcdn.com/images/cksgodl/post/a6768c89-e6b6-4cb7-9082-0e119a10d169/image.png)

- 프로듀서
  - 프로듀서는 부트스트랩 서버 목록을 사용하여 초기 메타데이터를 가져오고, 이를 기반으로 각 브로커와의 TCP 연결을 설정한다.
  - 프로듀서는 주기적으로 브로커로부터 메타데이터를 갱신하여 토픽과 파티션 정보를 최신 상태로 유지
  - 데이터 전송: 프로듀서는 브로커에 데이터를 전송할 때 Kafka의 바이너리 프로토콜을 사용하여 전달
- 컨슈머
  - 컨슈머는 부트스트랩 서버를 통해 초기 메타데이터를 가져오고, 해당 정보를 기반으로 브로커와의 TCP 연결을 설정한다.
  - 컨슈머는 브로커에 fetch 요청을 보내어 토픽의 데이터를 가져오며, 이 과정에서 TCP 연결을 유지한다.
     - Keep-Alive Connection (장기 TCP 연결 유지)
     - 브로커 -> Multiplexing (하나의 TCP 연결로 여러 요청 처리 가능)


> Kafka는 HTTP 같은 텍스트 기반 프로토콜이 아니라, **바이너리 프로토콜(Binary Protocol)**을 사용한다

![](https://velog.velcdn.com/images/cksgodl/post/e96d0141-554f-4eef-bbff-cec5a0302ade/image.png)

값을 바이트로 표현하기 때문에 사람이 직접 읽기엔 어려우나, 컴퓨터 입장에선 별도의 인코딩/디코딩이 필요 없으므로 빠르게 읽고 처리할 수 있다는 장점이 있다

메시지의 압축도 지원한다 -> Gzip, Snappy, LZ4 등

---

**발행/구독(publish/subscribe)**모델에서는 여러 시스템이 다양한 접근법을 사용한다.

#### 생산자가 소비자가 메시지를 처리하는 속보다 빠르게 메시지를 전송하면?

- 큐에 버퍼링한다. (배압, 흐름제어)
   - 큐가 가득차면?
   
#### 노드가 죽거나 일시적으로 오프라인이 된다면 메시지 손실?

- 디스크에 기록하거나, 복제본을 생성하거나 할 수 있다.
   - 트레이드 오프 설정
   
### 생산자에서 소비자로 메시지를 직접 전달하기

카프카와 달리 다른 많은 메시지 시스템은 브로커를 통하지 않고 생산자와 소비자를 네트워크로 직접 통신한다.

- UDP 멀티 캐스트는 낮은 지연이 필수인 주식 시장과 같은 금융 산업에서 많이 사용된다.
- StatsD과 BruBeck은 지표 수집및 모니터링에 UDP 메시징을 사용한다. 
- ZeroMQ같은 브로커가 필요없는 메시징 라이브러리도 있다.
- 웹훅(webhook)의 기본 아이디어로 서비스 콜백 URL을 다른 서비스에 등록하는 형식으로 이벤트가 발생할 때마다 콜백 URL로 요청을 보내는 형태도 있다.

직접 메시징 시스템은 메시지가 유실될 가능성을 고려한 코드 작성이 되야 한다.

### 메시지 브로커

직접 메시징 시스템의 대안으로는 **메시지 브로커(메시지 큐)**를 활용하는 방식이 있다.

![](https://velog.velcdn.com/images/cksgodl/post/9cd3c44c-c4bc-493d-957f-1e0583d96457/image.png)

- 브로커에 데이터가 모이기 때문에 클라이언트의 상태 변경에 쉽게 대처할 수 있다. 
- 브로커는 메시지를 디스크에 기록하며, 메시지 큐에 대한 설정을 진행한다.

### 메시지 브로커와 데이터베이스의 비교

- 데이터베이스는 메시지가 삭제될때까지 보관한다. 브로커의 경우는 기간, 용량에 따라 메시지를 삭제한다.
- 브로커의 경우 메시지큐가 가득차면 디스크에 보내고, 속도가 느려진다.

### 복수 소비자

![](https://velog.velcdn.com/images/cksgodl/post/8c99e1c7-3d57-40ae-bfd3-7f703d31a5b4/image.png)

복수 소비자가 같은 토픽에서 메시지를 읽을 떄 사용하는 주요 패턴이 있다.
![](https://velog.velcdn.com/images/cksgodl/post/a159464c-6ed2-4b6c-9ee7-7f89cc438e71/image.png)

#### 로드 밸런싱

메시지는 소비자 중 하나로 전달된다. 

#### 팬 아웃

각 메시지가 모든 소비자에게 전달된다. 여러 소비자가 브로드캐스팅된 동일 메시지를 
취할 수 있다.

### 확인과 응답

소비자가 메시지를 처리하지 못할 수도 있다. 이에따라 메시지 브로커는 **확인 응답**을 사용한다. 소비자가 메시지를 처리하면 브로커가 메시지를 큐에서 지울 수 있도록 명시적으로 알리는 것이다.

![](https://velog.velcdn.com/images/cksgodl/post/818f8701-75cd-4da9-9048-1c12f6a5ace2/image.png)

만약, 브로커가 확인 응답을 아직 받지 못했는데 클라이언트에 문제가 생겨 연결이 닫히거나 타임아웃되면 브로커는 메시지가 처리되지 않았다고 가정하고 다른 소비자에게 다시 전송한다. 

소비자2가 m3를 처리하던 도중 장애가 발생해 이후에 소비자 1로 재전송한다. 
문제가 발생했을 때 재전송하는 방식은 메시지 순서에도 영향을 줄 수 있다. 
위 그림을 보면 소비자1이 메시지 m4를 처리하고 있을 떄 소비자2가 메시지 m3를 처리하기에 에러가 발생한다. m3는 확인 응답을 받지 못해 소비자 1로 재전송된다. 

그 결과 소비자 1에선 m4 → m3 → m5 순으로 메시지를 처리한다. 

> 균형 분산과 메시지 재전송을 조합하면 필연적으로 메시지 순서가 변경된다.


## 파티셔닝된 로그

브로커의 메시지는 결국 삭제된다. 

브로커에 소비자가 추가되면 일반적으로 소비자를 등록한 시점 이후에 전송된 메시지부터 받기 시작된다. 이전 메시지는 복구할 수 없다.

**데이터베이스의 지속성 있는 저장 방법과 메시징 시스템의 지연 시간이 짧은 알림 기능을 조합할 수는 없을까?? 이것이 로그 기반 메시지 브로커(log-absed message borker)의 기본 아이디어다.**

### 로그를 사용한 메시지 저장소

로그는 단순한 레코드의 연속이다. 브로커는 받은 메시지를 로그로 활용하여 저장하고, 오프셋을 지정한다.

브로커는 모든 메시지에 오프셋이라 부르는 단조 순번을 부여한다. 이를 통해 파티션 내부의 메시지 순서를 보장한다.

![](https://velog.velcdn.com/images/cksgodl/post/93e16c26-5eef-4c55-b76e-a0d45d8a6421/image.png)


### 로그 방식과 전통적인 메시지 방식의 비교

로그 기반 접근법은 당연히 팬 아웃 메시지 방식을 제공한다. 독립적으로 로그를 읽고, 메시지는 로그에서 삭제되지 않는다.

각 클라이언트는 할당된 파티션의 메시지를 모두 소비한다. 일반적으로 소비자는 로그 파티션을 단일 스레드로 파티션에서 순차적으로 메시지를 읽는다. 

> Kafak Spring concurrent 설정

토픽 하나를 소비하는 작업을 공유하는 노드 수는 많아야 해당 토픽의 파티션 수로 제한된다.


### 소비자와 오프셋

브로커는 주기적으로 소비자의 오프셋을 기록한다. 오프셋은 단일 리더 데이터베이스 복제에서 널리 쓰이는 **로그 순차 번호**와 상당히 유사하다. 

### 디스크 공간 사용

로그를 추가하면 디스크공간은 결국 전부 사용하게 된다. 디크스 공간을 재사용하기 위해 실제로는 로그를 여러 조각으로 나누고, 가끔 오래된 조각을 삭제하거나 보관 저장소로 이동한다.

> 카프카에서는 디스크 공간을 활용하기 위해 기간, 크기를 지정할 수 있다. -> op log 기간과 비슷

```
log.retention.hours=168  # 7일 (시간 기준)
log.retention.minutes=10080  # 위랑 동일 (분 단위)
log.retention.ms=604800000  # 밀리초 단위 (7일)

log.retention.bytes=1073741824  # 1GB
```

+) 토픽 별 해당 기간을 다르게 지정할 수 있다.


브로커는 메시지 버퍼를 원형 버퍼, 링 버퍼로 유지하여 소비자가 너무 느려서 뒤쳐지면 메시지를 일부 잃어버릴 가능성이 있다. 

![](https://velog.velcdn.com/images/cksgodl/post/5a24d835-5f4e-4125-9c15-88d9e7539d0c/image.png)

### 소비자가 생산자를 따라갈 수 없을 때 

브로커는 일부 오래된 메시지를 버릴 수 있다. 소비자가 너무 느리면 이때 몇몇 메시지를 읽지 못할 수도 있다. 이는 사용자가 직접 모니터링하여 대처해야 한다.

이런 상황은 해당 소비자만 메시지를 잃어버리기에 다른 소비자의 서비스를 망치지 않는다. 이는 상당한 운영상의 장점이다.


### 오래된 메시지 재생

소비자는 본인의 메시지 오프셋을 변경할 수 있다. 따라서 소비자가 재처리할 수도 있기에 소비자의 동작을 멱등적으로 만드는 것이 좋다.

## 데이터베이스와 스트림

로그 기반 브로커는 데이터베이스에서 아이디어를 얻어 메시징에 적용하였다.

### 변경 데이터 캡쳐

**변경 데이터 캡쳐(Change Data Capture)**를 활용하여 데이터 변화를 감지하여 스트림으로 내보낼 수 있다.

![](https://velog.velcdn.com/images/cksgodl/post/bae8cefb-8ed7-497c-b945-5932bcb9e5a9/image.png)

몽고DB의 oplog를 읽고 이를 스트림으로 다시 내보내는 방식을 활용한다. (oplog 5만)

### 초기 스냅숏

모든 변경 사항을 여구적으로 보관하는 것은 공간이 너무 많이 필요하고, 오래거린다. 따라서 모두 적절하게 로그를 잘라서 사용한다. 


### 로그 컴팩션

**로그 컴팩션**을 통해 로그 크기를 줄일 수 있다.

저장 엔진은 주기적으로 같은 키의 로그레코드를 찾아 중복을 제거하고, 각 키에대해 중복된 내용을 제거한다. 

사용자는 오프셋 0부터 로그를 읽으면 현재 데이터베이스 상태를 만들 수 있다.

### 변경 스트림용 api 지원

카프카 커넥트는 카프카를 광범위한 데이터 시스템용 CDC로 활용하기 위해 여러 API를 제공한다. 

### 이벤트 소싱

**이벤트 소싱**은 DDD 기반에서 개발된 기법이다. 

이벤트 소싱은 어플리케이션의 상태 변화를 모두 변경 이벤트 로그로 저장한다. CDC와 큰 차이점은 추상화 레벨이 다르다는 점이다. 

- 이벤트 소싱은 어플리케이션 로직은 이벤트 로그에 기록된 로그 기반으로 구축한다. (갱신이나 삭제는 금지한다.) 

### 이벤트 로그에서 현재 상태 파생하기

이벤트 로그의 로그 컴팩션은 다르게 처리되어야 한다.


사용자 행동의 결과로 발생한 상태 갱신 메커니즘은 사용자 행동 의도를 표현한다. 이 경우 뒤의 이벤트가 앞선 이벤트를 덮어쓰지 않는다. 따라서 마지막 상태를 재구축하기 위해서는 이벤트 전체 히스토리가 필요하다.

### 명령과 이벤트 

이벤트 소싱의 철학은 **이벤트**와 **명령**을 구분하는데 주의한다. 

사용자 요청이 처음 도착했을 때 이 요청은 명령이다. 특정 무결성 조건을 위반하면 실패한다.
무결성이 검증되고 명령이 승인 되면 지속성 있는 불변 이벤트가 된다.

이벤트 불변 이벤트가 한번 생성되면 사실(fact)가 된다.
다시 변경 및 취소가 되었더라고 기존 정보는 여전히 사실로 남아 있으며, 다시 변경 및 취소는 나중에 추가된 독립적인 이벤트가 된다.

### 상태와 스트림 그리고 불변성

입력 파일의 불변성이 주는 이점

- 입력 파일에 손상을 주지 않고 기존 입력 파일에 얼마든지 처리 작업을 수행할 수 있다.
- 불변성 원리가 이벤트 소싱과 변경 데이터 캡처를 매우 강력하게 만든다


### 동일한 이벤트 로그로 여러 가지 뷰 만들기

불변 이벤트 로그에서 가변 상태로 분리하면, 동일한 이벤트 로그로 여러 읽기 전용 뷰(툴)를 만들 수 있다.

- 분석 데이터베이스 드루이드(Druid) : 카프카로부터 직접 데이터를 읽어 처리
- 카프카 커넥트 싱크(Kafka Connect Sink): 카프카에서 여러 데이터베이스와 색인에 데이터를 내보낼 수 있다.

기존 데이터를 새로운 방식으로 표현하는 새 기능을 추가하려면 이벤트 로그를 사용해 신규 기능용으로 분리한 읽기 최적화된 뷰를 구축할 수 있다.

- 기존 시스템을 수정할 필요가 없고 기존 시스템과 함께 운용이 가능하다.
- 신구 시스템을 나란히 구동하는 것은 기존 시스템에서 복잡한 스키마 이전을 수행하는 것보다 쉽다.

#### 명령 질의 책임의 분리(command query responsibility segregation, CQRS)

데이터를 어떻게 질의하고 접근하는지 신경 쓰지 않는다면, 데이터 저장은 상당히 직관적인 작업이다.데이터를 쓰는 형식, 읽는 형식을 분리해 다양한 읽기 뷰를 혀용한다면 상당한 유연성을 얻을 수 있다.

기존 아키텍쳐에서 점차 CQRS 패턴이 구현되는 모습. 마지막 단계에서 RDBMS와 NoSQL 간 데이터 이동은 Kafka와 같은 메시지 큐가 적용될 수 있다.

> 읽기 최적화된 뷰의 비정규화
>
> 데이터베이스와 스키마 설계의 전통적인 접근법은 데이터를 질의 받게 될 형식과 같은 형식으로 데이터를 기록해야 한다는 잘못된 생각에 기초한다.
>
>읽기 최적화된 뷰는 데이터를 비정규화하는 것이 전적으로 합리적이다

### 동시성 제어

이벤트 소싱과 변경 데이터 캡처의 가장 큰 단점은 이벤트 로그의 소비가 대개 비동기로 이뤄진다는 점이다. 사용자가 로그에 이벤트를 기록하고, 이어서 파생된 뷰를 읽어도 기록한 이벤트가 뷰에 반영되지 않았을 가능성이 있다. or 누락

보통 카프카를 활용하여 이벤트 로그를 파티셔닝하면, 간단한 단일 스레드 로그 소비자는 쓰기용 동시성 제어는 필요하지 않다.

### 불변성의 한계

선능적인 이유로 데이터를 삭제해야 하는 경우가 있다. 개인 정보 및 민감한 정보를 삭제해야 하는 경우도 있다. 하지만 데이터를 진짜로 삭제하는 작업은 어렵다. 많은 곳에 복제본이 남아 있기 때문이다.

삭제는 해당 데티러를 “찾기 불가능하게끔"하는 문제라기보다는 “찾기 어렵게"하는 문제이다.

## 스트림 처리

![](https://velog.velcdn.com/images/cksgodl/post/4ba435c9-4447-408b-9f77-06e5b80f70a2/image.png)

스트림을 처리하는 방법은 아래와 같다.

1. 이벤트에서 데이터를 꺼내 데이터베이스나 캐시,검색 색인 또는 유사한 저장소 시스템에 기록하고, 다른 클라이언트가 이 시스템에 해당 데이터를 질의한다. 
2. 이벤트를 사용자에게 직접 보낸다.
   - 이메일 경고, 푸시 알림, 실시간 대시보드
3. 하나 이상의 입력 스트림을 처리해 하나 이상의 출력 스트림을 생산한다.

스트림 처리자가 입력 스트림을 소비해 추가 전용 방식으로 다른 곳에 출력을 쓴다.
스트림을 처리하는 코드 조각을 연산자(operator)나 작업(job)이라 부른다.

### 스트림 처리의 사용

스트림 처리는 모니터링의 목적으로 오랜 기간 사용되어 왔다.

- 사기 감시 시스템의 신용카드 사용 패턴
- 금융 시장의 가격 변화 감지
- 공장의 기계 상태 모니터링: 오작동 감지
- 군사 첩보 시스템의 잠재적 침략자의 활동 추적


### 복잡한 이벤트 처리

![](https://velog.velcdn.com/images/cksgodl/post/625d83b7-198e-4788-8ff6-33cdd2a96e7e/image.png)

**복잡한 이벤트 처리(complex event processing, CEP)**

- 이는 이벤트 패턴 검색을 편리하게 제공하는 API이다.
- 정규 표현식으로 문자열에서 특정 문자 패턴을 찾는 방식과 유사함
- 질의는 처리 엔진에 제출하고 처리 엔진은 입력 스트림을 소비해 필요한 매칭을 수행하는 상태 기계를 내부적으로 유지한다.
- 해당 매치를 발견하면 엔진은 감지한 이벤트 패턴의 세부 사항을 포함하는, 글자 그대로 복잡한 이벤트(complex event)를 방출한다.

### 스트림 분석

스트림 분석은 대량의 이벤트를 집계하고 통계적 지표를 뽑는다.

- 특정 유형의 이벤트 빈도 측정
- 특정 기간에 걸친 값의 이동 평균(rolling average) 계산
- 이전 시간 간격과 현재 통계값의 비교

통계는 고정된 시간 간격 기준으로 계산한다. 집계 시간 간격을 윈도우(window)라 한다.

> 스트림은 대게 양이 많고 이를 처리하기위해 확률적 알고리즘을 사용하기도 한다.
>
> 집합 구성원 확인 용도의 블룸 필터, 원소 개수 추정 용도의 하이퍼로그로그 등
>
> - [확률적 자료구조를 이용한 추정 - 유일한 원소 개수(Cardinality) 추정과 HyperLogLog - D2](https://d2.naver.com/helloworld/711301)


### 구체화 뷰 유지하기

- 데이터베이스 변경에 대한 스트림은 파생 데이터 시스템이 원본 데이터베이스의 최신 내용 동기화.
   - 파상 데이터 시스템: 캐시, 검색 색인, 데이터 웨어하우스
- 어떤 데이터셋에 대한 또 다른 뷰를 만들어 효율적으로 질의할 수 있게 하고 기반이 되는 데이터가 변경될 때마다 뷰를 갱신한다.
- 이벤트 소싱에서 애플리케이션 상태는 이벤트 로그를 적용함으로써 유지된다.
  - 애플리케이션 상태는 일종의 구체화 뷰

### 메시지 전달과 RPC

메시지 전달 시스템을 RPC 대안으로 사용할 수 있다.
- 아파치 스톰: DRPC(Distributed RPC)
- GRPC
- KRPC

### 시간에 관한 추론

분석 목적으로 스트림을 처리하는 경우 시간을 다뤄야 할 때가 있다.
ex) 지난 5분 동안 평균(윈도우)

스트림 처리 프레임워크는 윈도우 시간을 결정할 때 처리하는 장비의 시스템 시계(처리 시간)를 이용한다. 이벤트 생성과 처리 사이의 간격을 확인하여 문제 발생을 예측할 수 있다.

보통 일괄 처리는 이벤트에 내장된 타임스탬프 이용하여 처리한다.

### 이벤트 시간 대 처리 시간

처리가 지연되는 이유는 다양한 상황이 있다.
- 큐 대기
- 네트워크 결함
- 메시지 브로커나 처리자에서 경쟁을 유발하는 성능 문제
- 스트림 소비자의 재시작
- 결함에서 복구하는 도중이나 코드 상의 버그를 고친 후 과거 이벤트의 재처리
- 이벤트 발생 시간과 처리 시간을 혼동하면 잘못된 데이터가 생길 수 있다.

![](https://velog.velcdn.com/images/cksgodl/post/27112299-7db8-4acb-be9f-f40ca8ba01f7/image.png)
위 사진은 스트림 처리자가 재시작한 상황: 1분간 스트림 처리가 셧다운됐다가 복구되어 백로그 이벤트를 처리하는 것이지만, 요청이 비정상 적으로 튀는 것 처럼 보인다.

### 준비 여부 인식

이벤트 시간 기준으로 윈도우를 정의할 때 낙오자(straggler)가 발생할 수 있다.

낙오자 이벤트를 처리하는 방법

- 낙오자 이벤트는 무시한다. 적은 비율일 때 무시하지만, 비율이 높아지면 알림을 보내는 방법으로 처리
- 수정 값을 발행한다. 이벤트가 포함된 윈도우를 기준으로 새로 갱신한 값


### 어떤 시계를 사용할 것인가?

이벤트가 발생한 머신과 이벤트를 처리하는 서버의 시간을 통해서 이벤트 발생 시간을 추정하는 방법(잘못된 장치 시계를 조정하는 방법)

이런 시간을 조정하려면 아래 세 가지 타임스탬프를 로그로 남겨서 조정할 수 있다.

- 이벤트가 발생한 시간(장치 시계)
- 이벤트를 서버로 보낸 시간(장치 시계)
- 서버에서 이벤트를 받은 시간(서버 시계) 

두 번째와 세 번째의 차이를 구하면 장치 시계와 서버 시계 간의 오프셋을 추정할 수 있다.
필요한 타임스탬프 정확도에 비해 네트워크 지연은 무시할 만하고 계산한 오프셋을 이벤트 타임스탬프에 적용해 이벤트가 실제로 발생 시간을 추정할 수 있다

### 윈도우 유형

이벤트 타임스탬프를 어떻게 결정할지 안다면 다음 단계는 윈도우 기간을 어떻게 정의해야 하는지 결정하는 일이다.
이벤트 수를 세거나 윈도우 내 평균값을 구하는 등 집계할 때 사용한다.

![](https://velog.velcdn.com/images/cksgodl/post/172534df-6d08-44b8-bb5c-421068db8c63/image.png)

## 스트림 조인

조인 작업은 일괄 처리 작업과 비슷하다.
하지만, 스트림 상에서 새로운 이벤트가 언제든 나타날 수 있다는 사실은 스트림 상에서 수행하는 조인을 일괄 처리 작업에서 수행하는 조인보다 어렵게 만든다.

이해를 위해 3가지 조인으로 나누어 설명한다.

### 스트림 스트림 조인(윈도우 조인) 

![](https://velog.velcdn.com/images/cksgodl/post/a53b3206-1f7a-410d-9c81-b8f0cc3741f5/image.png)

- 스트림과 스트림을 조인한다.
- 조인을 위한 적절한 윈도우 선택이 필요하다.
- 스트림 처리자가 상태(state)를 유지해야 한다.
- 검색, 클릭 이벤트가 발생할 때마다 해당 색인에 추가하고 스트림 처리자는 같은 세션ID로 이미 도착한 다른 이벤트가 있는지 다른 색인을 확인해야 한다.
- 이벤트가 매칭되면 검색한 결과를 클릭했다고 말해주는 이벤트를 방출한다

### 스트림 테이블 조인(스트림 강화)

- 데이터베이스로부터 데이터를 가져와서 이벤트 스트림과 조인한다.
    - 데이터베이스 과부화를 줄이기 위해 캐싱 활용
    - 하이브의 맵사이드 조인과 비슷
- 네트워크 왕복 없이 스트림 처리자 내부에 데이터베이스 사본을 적재한다.
- 사본 용량에 따라 메모리 내 해시테이블 또는 로컬 디스크에 넣을 수도 있다.
- 복사본을 최신 상태로 유지: 변경 데이터 캡처(change data capture, CDC)

스트림 스트림 조인과 비슷하지만, 테이블 변경 로그 스트림쪽은 “시작 시간"까지 이어지는 윈도우를 사용하며 레코드의 새 버전으로 오래된 것을 덮어쓴다 (G1, G2)

### 테이블 테이블 조인(구체화 뷰 유지)

양쪽 입력 스트림이 모두 데이터베이스의 변경 로그다. 한 쪽의 모든 변경을 다른 쪽의 최신 상태와 조인한다.

결과를 두 테이블을 조인한 구체화 뷰의 변경 스트림이 된다.

### 조인의 시간 의존성

상태를 유지하는 이벤트의 순서는 매우 중요하다. 시간에 따라 변하는 상태를 조인해야 한다면 어느 시점을 조인에 사용해야 할까?

복수 개의 스트림에 걸친 이벤트 순서가 결정되지 않으면 조인도 비결정적이다. 이를 **천천히 변하는 차원(slowly changing dimension, SCD)**라고 한다.

보통 조인되는 레코드의 특정 버전을 가리키는 데 유일한 식별자(unique identifier)를 사용해 해결한다. 세율이 바뀔 때마다 새 식별자를 부여하고 송장에는 판매 시점의 세율을 표시하는 식별자를 포함해야 한다.

이렇게 변경한 조인은 결정적이지만 테이블에 있는 레코드의 모든 버전을 보유해야 하기 때문에 로그 컴팩션이 불가능하다.

### 내결함성

일괄 처리(10장)는 일부 태스크가 실패할지라도 재처리가 가능하다. 하지만, 스트림 처리는 무한하다. 그래서 처리를 절대 완료할 수 없다. 

### 마이크로 일괄 처리와 체크 포인트

내결함성의 한 가치 해결책은 스트림을 작은 블럭으로 나누어 관리하는 방식이다.

**마이크로 일괄처리(microbatching)**: 스트림을 작은 블록으로 나누고 각 블록을 소형 일괄 처리와 같이 다루는 방법
- 스파크 스트리밍에서 사용
- 처리 크기는 약 1초 정도
- 처리 크기가 작을수록 스케줄링과 코디네이션 비용이 커진다
- 처리 크기가 클수록 스트림 처리의 결과를 보기까지 지연시간이 길어진다

다른 해결책으로써는 중간 상태를 저장하는 방식이다.

**체크포인트(checkpoint):** 주기적으로 상태의 롤링 체크포인트를 생성하고 지속성 있는 저장소에 저장한다.
- 아파치 플링크
* 스트림 연산자에 장애가 발생하면 스트림 연산자는 가장 최근 체크포인트에서 재시작하고 해당 체크포인트와 장애 발생 사이의 출력은 버린다.

두 가지 접근법만으로는 이 문제를 방지하기에 충분하지 않다.

#### 원자적 커밋 재검토

장애가 발생했을 때 정확히 한 번 처리되는 것처럼 보일려면 처리가 성공했을 때만 모든 출력과 이벤트 처리의 부수 효과가 발생하게 해야 한다.

원자적이거나 동기화되어야함

#### 멱등성(idempotence)

결국 목표는 처리 효과가 두 번 나타나는 일 없이 안전하게 재처리하기 위해 실패한 태스크의 부분 출력을 버리는 것

* 멱등 연산: 여러 번 수행하더라도 오직 한 번 수행한 것과 같은 효과를 내는 연산

연산 자체가 멱등적이지 않아도 약간의 여분 메타데이터로 연산을 멱등적으로 만들 수 있다.
모든 메시지에는 영속적이고 단조 증가하는 오프셋이 있다.
트리거한 메시지의 오프셋을 함께 포함한다면 이미 갱신이 적용됐는지 확인할 수 있기 때문에 반복해서 같은 갱신이 수행되는 것을 막을 수 있다.

#### 실패 후에 상태 재구축하기

원격 데이터 저장소에 상태를 유지하고 복제하는 것
스트림 처리자의 로컬에 상태를 유지하고 주기적으로 복제하는 것
모든 트레이드오프는 기반 인프라스트럭처의 성능 특성에 달려있다.

## 정리

- 메시지 브로커는 보통 로그 기반 메시지 브로커로 이루어진다.
- 스트림은 데이터가 끊임없이 들어오고, 이를 관리하기 위해 로그 컴팩션을 활용할 수 있다.
- 변경 로그 (CDC)를 활용해 검색 색인, 캐시, 구체화 뷰를 항상 최신 상태로 유지할 수 있다.
- 스트림 조인의 형태로 3가지 형태로 나눈다.
   - 스트림 스트림 조인
   - 스트림 테이블 조인
   - 테이블 테이블 조인
   
 
 