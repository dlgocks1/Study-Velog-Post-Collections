## 레코드 시스템과 파생 데이터 시스템

데이터를 저장하고 처리하는 시스템은 크게 두 분류로 나뉜다.

- 레코드 시스템
  - 레코드 시스템은 믿을 수 있는 데이터 버전을 통체로 저장한다. 
     - 이는 **진실의 근원(source of truth)**이라고 불리기도 한다. 새로운 데이터가 들어오면 이는 일단 레코드 시스템에 저장된다.
- 파생 데이터 시스템
  - 파생 데이터 시스템은 이미 존재하는 데이터를 가져와 변환하고 처리한 결과이다. 이는 **데이터가 아니라 정보이다.**
  
> 파생 데이터는 기존 데이터를 복제한다는 의미에서 **중복(redundant)**가 발생할 수 있다. 하지만 이는 읽기 질의 성능을 높이는데 종종 필수적이며 데이터가 아니라 **정보**를 볼 수 있게 한다.

![](https://velog.velcdn.com/images/cksgodl/post/74a9ee15-2360-4814-b625-282e465a0a57/image.png)

## 데이터 처리

데이터 처리 시스템은 크게 3가지로 나뉜다.

- 서비스(온라인)
  - 낮은 응답속도를 필요로 한다.
- 일괄 처리 시스템(오프라인 시스템)
  - 처리량이 주요 지표이며, 대개 사용자가 작업이 끝날때 까지 대기하지 않는다.
- 스트림 처리 시스템(준 실시간 시스템)
  - 스트림 처리는 일괄 처리를 기반으로 작동하고, 일괄처리와 온라인 처리의 중간에 있다.
  
> 대표적인 일괄처리 알고리즘으로는 MapReduce가 있으며, 몽고DB, 하둡 등에서 제공한다.

### 유닉스 철학

- 각 프로그램이 한 가지 일만 하도록 작성하라. 
- 새 작업을 하려면 기존 프로그램을 고쳐 확장하기보단 새로운 프로그램을 작성하라.
- 모든 프로그램의 출력은 어디서든 입력으로 사용될 수 있다고 생각하라.
- 출력이 너저분해서는 안된다.
  - Ex: 이진 형태, 엄격한 열 맞춤 등
- 소프트웨어를 빠르게 써볼 수 있게 설계하고 구축하라. 
- 프로그래밍 작업을 줄이려면 도구를 사용하라. 

사실상 요즘 현대적인 개발 방법론들과도 크게 다르지 않다.(Ex: Agile, DevOps)

### 동일 인터페이스

유닉스는 동일한 입출력 인터페이스를 사용해서 호환성을 높힌다. (파일 디스크립터) 유닉스에서의 인터페이스는 파일 디스크립터로 단순하게 순서대로 **정렬된 바이트**의 연속이다. 

단순하기 때문에 동일한 인터페이스로 파일시스템의 실제 파일 프로세스 간 
- 통신 채널(유닉스 소켓, 표준 입력(stdin), 표준 출력(stdout)) 
- 장치 드라이버(/dev/audio, /dev/lp0등) 
- TCP 연결을 나타내는 소켓

등 다른 여러가지 것을 표현할 수 있다. 이런 동일 인터페이스는 여전히 대단하다.

> **동일한 데이터 모델**인 데이터베이스 간에도 한쪽에서 한쪽으로 데이터를 옮기는 것이 쉽지 않다. 데이터가 분화발전하는 이유는 유닉스 도구와 같은 통합 도구가 부족했기 때문이다.

### 로직의 연결과 분리

유닉스에서는 `stdin`, `stdout`을 통해 로직을 연결한다. 이러한 형태를 **느슨한 결합(losse coupling), 지연 바인딩(late binding), 제어 반전(inversion of control)**이라고 하기도 한다.

## 맵리듀스와 분산 파일 시스템

![](https://velog.velcdn.com/images/cksgodl/post/3503a676-f08e-4d17-8b76-063bf793e24a/image.png)

맵 리듀스는 수천 대의 장비를 분산하여 연산을 실행할 수 있다.

유닉스는 `stdin`, `stdout`을 표준 입출력으로 사용하지만, 하둡의 맵리듀스 작업은 파일의 입력과 출력으로 사용한다. 

  - 여기서 하둡은 `HDFS(Hadoop Distributed File System`)이라고도 하며, `GFS(Google File System)`을 재구현한 오픈소스이다.

> 하둡은 **비공유 원칙**을 기반으로 작동된다. (하드웨어가 아니라 데이터센터 네트워크에 연결된 컴퓨터들로 작동한다.)

하둡은 각 장비에서 실행되는 데몬 프로세스로 구성된다. 데몬 프로세스가 실행되어 다른 노드가 파일에 접근할 수 있게 한다. 이 때 네임노드라는 중앙 서버가 파일 블록의 위치를 추적한다.

HDFS는 분산된 하나의 큰 파일 시스템으로 간주되며, 장비 실패에 대비하여 파일 블록이 여러 장비에 복제된다. 여러 복제 방식이 있으며, 저장소 부담을 줄이는 **삭제 코딩(Earsure Coding) 방식**도 사용된다.

> **삭제 코딩 방식(Erasure Coding)이란?**
>
>삭제 코딩(Erasure Coding, EC)은 데이터를 여러 개의 조각으로 나누고, 일부 조각이 손실되더라도 원본 데이터를 복구할 수 있도록 설계된 데이터 보호 기술. RAID(특히 RAID 5, 6)와 비슷한 개념이지만, 더 유연하고 효율적인 방식으로 분산 시스템에서 널리 사용된다. 🚀
> 
> 삭제 코딩은 데이터를 k 개의 데이터 블록과 m 개의 추가적인 패리티(Parity) 블록으로 나눈다
![](https://velog.velcdn.com/images/cksgodl/post/68012494-205e-4d37-b1a3-909fdfafcefe/image.png)
> 즉 : k 개의 블록만 있으면 원본 데이터를 복구할 수 있음

HDFS은 확장성이 뛰어나며, 비용 효율적인 대규모 데이터 저장 및 접근을 가능하게 한다.

### 맵리듀스 작업 실행하기

맵리듀스는 `HDFS`같은 분산 파일 시스템 위에서 대용량 데이터를 처리하는 프로그래밍 프레임워크다.
맵 리듀스 작업 하나는 4가지 단계로 수행한다.

1. (`Splitting`)
입력 파일을 읽고, 레코드로 쪼갠다. 
웹 서버 로그 예제에서 로그의 각 줄이 레코드가 된다. 
레코드 분리자로 \n을 사용한다.
2. (`Mapping`)
각 입력 레코드마다 매퍼 함수를 호출해 키와 값을 추출한다. 
3. (`Shuffling`)
키를 기준으로 키-값 쌍을 모두 정렬한다. 이 과정은 로그 예제에서 첫 번째 sort 명령에 해당한다.
4. (`Reducing`)
정렬된 키-값 쌍 전체를 대상으로 리듀스 함수를 호출한다.

![](https://velog.velcdn.com/images/cksgodl/post/3fccdb90-f206-4c0d-8111-48788c090f8b/image.png)

`2단계(맵)`과 `4단계(리듀스)`는 사용자가 직접 작성한 데이터 처리 코드다. 맵 리듀스 작업을 생성하려면 다음과 같이 동작하는 매퍼와 리듀서라는 두 가지 콜백 함수를 구현해야 한다. 

- 매퍼(Mapper)
  - 매퍼는 모든 입력 레코드마다 한 번씩만 호출되며 입력 레코드로부터 다음 레코드까지 상태를 유지하지 않기 때문에 각 레코드를 독립적으로 처리한다.
- 리듀서(Reducer)
  - 맵리듀스 프레임워크는 매퍼가 생산한 키-값 쌍을 받아 같은 키를 가진 레코드를 모으고 해당 값의 집합을 반복해 리듀서 함수를 호출한다. 

> 몽고에서의 MapReduce(Deprecated by Aggregation)
>
> 
```js
var mapFunction = function() {
    emit(this.category, this.amount);  // 카테고리를 키로 사용, 판매 금액을 값으로 사용
};
var reduceFunction = function(key, values) {
    return Array.sum(values);  // 같은 카테고리 값을 더함
};
db.sales.mapReduce(
    mapFunction,
    reduceFunction,
    { out: "sales_totals" }  // 결과를 저장할 컬렉션
);
```

### 맵 리듀스의 분산 실행

맵리듀스의 가장 큰 장점은 여러 장비에서 병렬 실행이 가능하다는 것이다. 맵리듀스 작업은 파티셔닝을 기반으로 작동한다. 

아래 그림에서 맵 태스크를 m1, m2, m3로 표시했다. 

> 입력 파일의 복제본이 있는 장비에 RAM과 CPU에 여유가 충분하다면 맵리듀스 스케줄러가 입력 파일이 있는 장비에서 작업을 수행하려 한다. 이 원리를 데이터 **가까이에서 연산하기**라 하는데, 이 원리를 적용하면 네트워크를 통해 입력 파일을 복사하는 부담과 네트워크 부하가 감소하고 지역성이 증가한다. 

![](https://velog.velcdn.com/images/cksgodl/post/ce32d468-8c4e-4161-97a5-3f1c5693c038/image.png)

- 맵 태스크의 수는 입력 파일의 블록 개수(위에서는 m1, m2, m3 세 개)로 결정되고 리듀스 태스크는 사용자가 설정할 수 있다. 
  - 맵 태스크의 수는 클러스터의 하드웨어 구성, 데이터의 크기, 작업의 복잡도 등 여러 요소에 따라 결정될 수 있다. 
- 매퍼의 출력은 키-값 쌍으로 구성된다. 
   - 같은 키를 가진 모든 키-값 쌍을 같은 리듀서에서 처리하는 것을 보장한다. 
   - 각 맵 태스크는 키의 해시값을 기반으로 출력을 리듀서로 파티셔닝한다. 
- 그 다음 각 파티션을 매퍼의 로컬 디스크에 정렬된 파일로 기록한다. 
   - 이는 LSM트리의 구성과 비슷하게 작동한다.
- 기록이 완료되면 맵리듀스 스케줄러는 매퍼에서 출력 파일을 가져올 수 있다고 리듀서에게 알려준다.
- 리듀서는 각 매퍼와 연결해 리듀서가 담당하는 파티션에 해당하는 키-값 쌍 파일을 다운로드한다.
- 리듀서를 기준으로 파티셔닝, 정렬, 매퍼로부터 데이터 파티션을 복사하는 과정을 셔플(shuffle)이라 한다.
   - 리듀스 태스크는 매퍼로부터 파일을 가져와 정렬된 순서를 유지하며 병합한다. 
- 매퍼와 리듀서는 서로 다른 머신에서 실행되는데, 이 때 데이터 전송에 네트워크 비용이 발생할 수 있다. 
- 리듀서는 임의의 로직을 사용해 이 레코드들을 처리하고 여러 출력 레코드를 생성할 수 있으며 이 출력 레코드는 분산 파일 시스템에 파일로 기록된다. 

![](https://velog.velcdn.com/images/cksgodl/post/fd4beb6d-2987-46d5-b0ad-b01b2ce7526d/image.png)

### 맵 리듀스 워크플로

맵리듀스 작업을 연결해 워크플로(workflow)로 구성할 수 있다. 이는 맵리듀스 작업 하나의 출력을 다른 맵리듀스 작업의 입력으로 사용하는 방식이다. 

연결된 맵리듀스 작업은 유닉스 명령 파이프라인보단 각 명령의 출력을 임시 파일에 쓰고 다음 명령이 그 임시 파일로부터 입력을 읽는 방식에 더 가깝다. 

이러한 작업 스케줄을 위해 **아즈카반**, **에어플로우**등을 활용할 수 있다.

### 리듀스 사이드 조인과 그룹화

관계형 모델에서는 외래키(foreign key), 문서 모델에서는(document reference), 그래프 모델에서는 간선(edge)를 통해 조인하고, 필요한 데이터를 가져온다. 또한 색인(index)를 통해 레코드를 빨리 찾는다. 하지만, 이런 개념들은 맵리듀스에는 없다.

파일 집합이 입력으로 주어짐으로 맵리듀스작업은 **전체 테이블 스킨(full table scan)**이라 부른다. 특정 사용자의 정보를 찾기에는 효율적이지 않다.

### 사용자 활동 이벤트 분석 예제

![](https://velog.velcdn.com/images/cksgodl/post/a8de7b44-9537-421f-ab4e-68989e3625d4/image.png)

왼쪽은 로그인 사용자가 웹사이트에서 활동한 이벤트로그 활동 이벤트(activity event) 또는 클릭스트림 데이터(clickstream data))
우측은 사용자 데이터베이스이다. 

활동 이벤트에 사용자 프로필 DB를 조인해야 한다. 이 조인을 간단하게 구현하는 방법은 활동 이벤트를 하나씩 훑으며 모든 사용자 ID마다 원격 서버에 있는 사용자 DB에 질의를 보내는 것이지만, 과부하로 성능에 문제가 있을 확률이 높다. 

따라서, `DB`의 사본을 가져와 사용자 활동 이벤트 로그가 저장된 분산 파일 시스템에 넣는 방법을 사용할 수 있다. 그러면 사용자 데이터베이스와 사용자 활동 레코드가 같은 HDFS 상에 존재하고 맵리듀스를 사용해 연관된 레코드끼리 모두 같은 장소로 모아 효율적으로 처리가 가능하다. 

### 정렬 병합 조인

두 개의 정렬된 집합을 병합하여 조인하는 알고리즘이다.

![](https://velog.velcdn.com/images/cksgodl/post/6f91c2c7-f47b-46fa-9121-31ac3ee80238/image.png)

리듀서가 사용자 DB를 보고 활동 이벤트의 시간을 기반으로 병합하며 조인한다. 이를 **보조 정렬(secondary sort)**라고도 한다.

- 두 개의 입력 테이블이 정렬된 상태여야 함
- 각 테이블을 순차적으로 읽으며 병합(merge)하면서 조인
- 대량의 데이터 처리에 적합
- 인덱스가 없을 때도 사용 가능, 하지만 정렬 비용이 추가될 수 있다.

### 같은 곳으로 연관 데이터 가져오기

병합 정렬 조인 결과는 모든 데이터를 한 곳으로 모으고, 그렇기에 사용자 ID별로 리듀서를 한 번만 호출한다. 

필요한 데이터는 미리 정렬했기에 리듀서는 높은 처리량과 낮은 메모리 사용량을 가질 수 있다. 

매퍼가 키-값 쌍을 보낼 때 키는 목적지의 주소 역할을 한다.

### 그룹화

데이터 그룹화는 특정 키를 기준으로 레코드를 묶는 것으로, SQL에서의 **GROUP BY**절과 유사하다. 그룹화된 데이터에 대해 다양한 집계 연산을 수행할 수 있다.

각 그룹의 레코드 수를 카운트(페이지뷰 카운트 예제와 같이 SQL로는 COUNT(*)로 표현할 수 있다.)

맵리듀스에서 그룹화를 구현하는 방법은 매퍼가 키-값 쌍을 생성할 때 그룹화할 대상을 키로 사용하는 것이다. 그 결과, 같은 키를 가진 모든 레코드가 같은 리듀서로 모이게 된다.

### 쏠림 다루기

불균형한 활성 데이터베이스 레코드를 **린치핀 객체(linchipin obejct)** 또는 **핫 키(hot spot)**이라 한다.

유명인사의 트윗에 한 리듀서에 상당한 쏠림 현상이 발생할 수 있다.(**핫스팟**) 

**모든 매퍼와 리듀서가 끝나야지 맵리듀스 작업이 끝나기 때문에 가장 느린 리듀서가 작업을 완료할 때 까지 후속 작업들은 시작하지 못한다.**

#### 쏠린 조인(skewed join) 

**핫 키(Hot Key, 특정 키가 너무 많음)**를 분산시키기 위해 가짜 키(Fake Key)를 추가할 수 있다. 즉, 데이터를 여러 개의 그룹으로 나누어 병렬 처리한다.

1️⃣ 핫 키가 아닌 데이터는 그대로 조인
2️⃣ 핫 키는 여러 개의 파티션으로 나눠서 조인

```kotlin
val skewedOrders = orders
  .withColumn("random_key", expr("user_id + floor(rand() * 10)")) // 가짜 키 추가

val skewedUsers = users
  .withColumn("random_key", expr("user_id")) // 동일한 가짜 키 추가

val result = skewedOrders
  .join(skewedUsers, "random_key") // 가짜 키 기준으로 조인
```

#### 공유 조인(Broadcast Join)

작은 테이블과 큰 테이블 조인 시 병목 발생한다. 따라서 작은 테이블을 전체 노드에 복제(브로드캐스트)해서 빠르게 조인할 수 있다.

_기본적인 조인은 큰 테이블을 전체적으로 셔플링해야 하므로 비효율적_

---

하이브(Hive)의 경우 쏠린 조인을 최적화할 때 다른 방법을 사용한다. 핫 키는 테이블 메타데이터에 명시하고, 핫 키와 관련된 레코드를 나머지 키와 별도 파일에 저장한다. 해당 테이블에서 조인할 때 핫 키를 가지는 레코드는 맵 사이드 조인을 사용해 처리한다.

### 맵 사이드 조인

조인 알고리즘의 실제 로직을 리듀서에서 수행하는 것을 **리듀스 사이드 조인**이라 한다. 이때 매퍼는 키와 값을 추출해 추출한 키-값 쌍을 리듀서 파티션으로 할당하고 입력 데이터를 준비하는 로직을 수행한다.

> **맵 사이드 조인(Map-Side Join)이란?**
>
>💡 맵 리듀스(MapReduce)에서 리듀스 단계를 거치지 않고, 맵 단계에서 바로 조인하는 기법
즉, 네트워크 셔플링 비용을 줄이고 속도를 극대화하는 조인 방식

한쪽 테이블이 매우 작아야 하며, 작은 테이블을 각 노드에 미리 배포(Distributed Cache)한다. 맵 단계에서 큰 테이블의 데이터를 처리하면서 작은 테이블을 조회하여 조인을 수행한다.

![](https://velog.velcdn.com/images/cksgodl/post/a5aebb0c-9bef-49a1-82b2-4e72d7cc590a/image.png)


### 브로드캐스트 해시 조인

![](https://velog.velcdn.com/images/cksgodl/post/d6998441-d98e-4d29-8f87-c2689c55a2ff/image.png)


맵 사이드 조인은 작은 데이터셋과 매우 큰 데이터셋을 조인하는 경우에 가장 간단하게 적용할 수 있다. 이는 작은 테이블을 인메모리 해시 테이블에 넣고 이를 조인한다. **이런 간단하고 효율적인 알고리즘을 브로드캐스트 해시 조인이라 한다.** 

### 파티션 해시 조인
![](https://velog.velcdn.com/images/cksgodl/post/1a9fdba3-968b-4982-986f-5c78a8f2d8ff/image.png)

맵 사이드 조인의 입력을 파티셔닝한다면 각 파티션에 독립적으로 해시조인할 수 있다. 파티셔닝 된 레코드는 모두 같은 번호의 파티션에 위치한다. 따라서 각 매퍼 테이블에 적재해야할 데이터의 양을 줄일 수 있다.

> 파티션 해시 조인을 하이브에서는 버킷 맵 조인이라 한다.

### 맵 사이드 병합 조인

입력 데이터가 **같은 방식으로 파티셔닝 + 같은 키로 정렬** 이라면 변형 맵사이드 조인을 적용할 수 있다. 수행과정은 양쪽 모두 오름차순으로 키를 읽어 동일한 레코드를 간단하게 맞춘다.

### 일괄 처리 워크플로 출력 값

이런 조인은 대규모 레코드를 스캔해 집계 연산을 하기 위해 사용된다. 이는 주로 분석을 위해 사용되며 이런 작업의 워크플로우는 분석 목적의 SQL과는 다르다.

### 검색 인덱스 구축

정해진 문서 집합을 대상으로 전문 검색이 필요하다면 일괄 처리가 인덱스를 구성하는데 매우 효율적이다. 매퍼는 필요에 따라 문서 집합을 파티셔닝하고 각 리듀서가 해당 파티션에 대한 인덱스를 구축한다. (색인 파일은 분산 파일 시스템에 저장된다.) 

다른 방식으로 인덱스를 만들 수 있다. SS테이블의 예처럼 세그먼트 파일을 새로 기록하고 백그라운드에서 증분식으로 파일을 병합하는 방식이 가능하다.

### 일괄 처리의 출력으로 키-밸류 저장

이러한 일괄처리의 결과는 흔히 일종의 데이터베이스가 된다. 이같은 데이터베이스는 하둡 인프라와 별도로 사용자 요청을 받는 웹 어플리케이션에서 질의해야 한다. 배치 프로세스의 출력을 웹 어플리케이션이 질의하는 데이터베이스 형태로 내보내는 방법을 알아본다.

가장 확실한 방법은 리듀서내에서 선호하는 데이터베이스 클라이언트 라이브러리를 활용해 일괄 처리 하는 작업이다. 하지만 이는 데이터베이스 부하, 실패 시 내결함성 부족 등 다양한 이슈가 따른다.

훨씬 좋은 해결책은 일괄 처리 작업 내부에 완전히 새로운 데이터베이스를 구축해 분산 파일 시스템에 저장하는 방식이다. HBase가 벌크 적재를 활용한다. 

### 일괄 처리 출력에 대한 철학

맵 리듀스 작업은 유닉스 철학에 따라서 입력이 변하지 않는 한 출력이 변하지 않아야한다.  또한 좋은 성능을 내면서도 훨씬 간단하다.

- 데이터가 오염되면 이전 버전으로 돌리고 재수행하면 된다.
  - 애자일 소프트웨어 개발에 이롭다.
- 맵이나 리듀스 작업이 실패하면 프레임워크가 자동으로 재시작한다.
  - 이런 작업이 안전한 이유는 입력이 불변이기 때문이다. 

### 저장소와 다양성

데이터 베이스는 관계형, 문서형이든 모델에 따라 데이터를 구조화 해야한다. 하지만 분산 파일시스템의 파일은 어떤 데이터 모델과 인코딩을 사용해서도 기록할 수 있는 연속된 바이트일 뿐이다. (이는 어떠한 형태라도 저장된다.)

> **커다란 조직에서 다양한 데이터를 한 곳으로 모으는 작업만으로도 큰 가치가 있다.** 이전에는 이질적이던 데이터셋을 조인 가능하게 만들어주기 떄문이다. 세심한 스키마설계는 중앙 집중식 데이터수집을 느리게 만든다. 따라서 원시 데이터를 수집하고 스키마 설계는 나중에 고민하면 데이터 수집의 속도가 올라간다.(데이터 호수라고 알려진 개념)

![](https://velog.velcdn.com/images/cksgodl/post/c90cfecc-4231-4d1a-96f6-0cf184b55f84/image.png)

- [빅데이터로 가치를 만드는 호수 ‘데이터 레이크’ 이야기](https://www.samsungsds.com/kr/insights/big_data_lake.html)

이런 데이터 덤핑은 데이터 해석의 부담을 소비자에게 부담시킨다. (Schema on read) 이는 나쁜 것이 아니다. 원시 상태로 데이터를 덤프하기만 하는 것으로도 여러 변환이 가능하다. 이 접근법은 초밥 원리(sushi principle)라 부른다.

![](https://velog.velcdn.com/images/cksgodl/post/ad4f4038-77c2-41a4-8dda-d9b53e5a9784/image.png)

### 처리 모델의 다양성

SQL를 활용하여 비즈니스 분석 툴로 활용할 수 있다. 하지만 모든 종류의 처리를 표현하지는 못한다. 따라서 이를 위해서는 코드 작성이 반드시 필요하다.

> HDFS + 맵리듀스가 있으면 그 위에 SQL 질의 실행 엔진을 구축할 수 있는데 **하이브 프로젝트**가 바로 그런 역할을 수행한다. 

### 빈번하게 발생하는 결함을 줄이는 설계

맵리듀스와 MPP 데이터베이스의 큰 차이점은 아래와 같다.
- 결함을 다루는 방식
- 메모리 및 디스크를 사용하는 방식


MPP 데이터베이스는 대부분 한 장비만 죽어도 전체 질의가 중단된다. 일반적인 질의는 수 초, 수 분에서 끝나기 때문에 재시도 비용이 크지 않아 재시도로 수행한다. 

하지만 맵리듀스의 경우는 맵 또는 리듀스의 개별 태스크 실패를 견딜 수 있다. 개별 태스크 수준에서 작업을 수행하고, 디스크에 올리기 때문에 해당 태스크만 재실행하면 된다. (전체 테스크를 재실행 할 필요 없다.)

> 즉, 맵리듀스는 태스크 종료가 예상치 못하게 자주 발생하더라도 견딜 수 있게 설계됐다. 프로세스를 임의로 종료할 수 있으면 연산 클러스터에서 자원 활용도를 높일 수 있기 때문이다. 
>
> _우선순위 테스크에 따라 선점(preempt)이 작동하기 때문_


## 맵리듀스를 넘어

맵 리듀스의 추상화는 정말 단순하게 구현되어 있지만, 원시 API를 활용하여 연산을 구현하는 일은 쉽지 않다. 

따라서 추상화된 맵리듀스를 직접 사용하는 일은 어렵지 않고 이에 따라 다양한 고수준 모델(피그, 하이브, 크런치)등이 등장했다. 이를 통해 일괄 처리 테스크를 쉽게 구현할 수 있다.

### 중간 상태 구체화

맵리듀스 작업(테스크)은 다른 작업과 모두 독립적이다. 첫 번째 작업과 두 번째 작업은 서로 각 입력 및 출력 디렉토리에 의존하여 실행된다. (디스크에 중간 상태가 쓰여진다.)

> 이런 중간 상태를 파일로 기록하는 과정을 구체화(materialization)이라 한다.

_책에서는 이러한 작업을 테스크 단위 배치 형식으로 진행하여 단점이 있다고 하지만, 이는 감수할만 하다. (선행 작업이 완료되었을 때만 실행, 매퍼 중복, 중간 파일이 여러 파일로 복제)_

### 데이터 플로 엔진

맵리듀스를 활용하는 데이터 플로 엔진이 개발되었는데 그 중 **스파크**가 가장 널리 알려진 엔진이다.

![](https://velog.velcdn.com/images/cksgodl/post/e1954197-764b-4404-938e-e9b32890f1e2/image.png)

이는 전체 워크플로를 독립된 하위 작업으로 나누지 않고 작업 하나로써 다룬다. 이는 맵과 리듀스를 번갈아 수행하는 규칙을 지키지 않고, **연산자(operator)**를 활용하여 연산자의 출력과 입력을 연결하는 여러 선택지를 제공한다. 

- 정렬 작업이 항상 발생하지 않는다.
- 지역성 최적화 가능
- 중간 상태 저장 I/O가 훨씬 적다. (메모리나 로컬 디스크에만 저장)
- 존재하는 JVM을 활용할 수 있다.

이러한 최적화를 통해 연산 수행 속도가 훨씬 빠르다.

#### 선언형 질의 언어로 변환

하이브, 스파크 등의 프레임워크는 발전하여 내부에 질의 최적화기를 내장하고 있다. 이는 중간상태를 최소화하기 위해 조인 순서를 바꾸기도 한다.

### 내결함성

데이터의 재연산시 동일한 결과가 출력되어야한다. 이를 **연산이 결정적**이다 라고 한다. 이는 프레임워크단에서 내결함성으로 제공할 수도 있지만, 어플리케이션 코드를 작성할 때도 연산이 **결정적**으로 동작하도록 작성해야 한다.

## 정리

유닉스 철학을 계승하여 맵리듀스가 등장하였다. 이는 복잡한 문제도 "한 가지 일을 잘하는" 작은 도구를 엮어서 해결한다.

분산 일괄 처리 프레임워크가 해결해야할 두 가지 문제가 있다.

- 파티셔닝
  - 맵리듀스의 매퍼는 입력 블록에 따라 파티셔닝 된다. 
- 내결함성
  - 개별 테스크가 실패하더라도 전체 작업을 재 수행하지 않고 복구할 수 있다. 현재 데이터플로 엔진은 중간 상태를 최대한 구체화 하지않고 메모리에 들고 있는다 따라서 결정적 연산자를 활용하여 필요한 데이터의 양을 줄일 수 있다.
  
  
또한 맵 리듀스에서 사용하는 몇가지 조인 알고리즘도 살펴보았다.

- 정렬 병합 조인
  - 조인 키를 추출하는 매퍼를 통합시켜 리듀서에서 조인된다.
- 브로드캐스트 해시 조인
  - 입력 중 하나가 상대적으로 작다면 해시 테이블에 모두 적재하여 조인한다. 매퍼가 시작할 때 각 매퍼에 작은 입력으로 만들어진 해시테이블을 적재하고 조인한다.
- 파티션 해시 조인
  - 조인 입력 두개를 같은 방식으로 파티션하면 각 파티션이 조인되어 사용된다. (같은 키, 같은 함수, 같은 파티션 수)
  
  
  











