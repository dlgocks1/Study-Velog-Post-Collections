## 결함과 부분 장애

컴퓨터는 우리 생각대로 동작하지 않는다. 하지만 언제나 잘못된 것은 사람이다. 우리는 우리의 잘못으로 컴퓨터 결함이 발생하면 잘못된 결과보다는 완전히 동작하지 않기를 바란다. 잘못된 동작은 다루기 어렵기 떄문이다.

분산 시스템에서의 장애는 **부분 장애(partial failure)**을 낳는다. 이는 비결정적이라 어렵다.

### 클라우드 컴퓨팅과 슈퍼 컴퓨팅

- 슈퍼 컴퓨터 : 고성능 CPU로 작업을 처리한다.
  - 노드 하나에 장애 발생시 흔한 해결책으로는 전체 클러스터 작업 부하를 중단한다.
  - 장애 복구 이후엔 마지막 체크포인트부터 재시작한다.
  - 분산 시스템보다는 단일 노드 컴퓨터에 가깝다.
  - 부분 장애를 전체 장애로 확대하는 방법으로 처리한다. 

- 클라우딩 컴퓨팅 : 많은 CPU로 부하를 나눠서 처리한다.
  - 인터넷 관련 애플리케이션은 사용자에게 지연 시간이 낮은 서비스를 제공해야 하기 때문에 클러스터 중단을 할 수 없다. 
  - 상용 장비를 사용해 구축하는데, 규모의 경제를 이유로 비용대비 높은 성능을 제공하지만 실패율도 높다. 
  - 지리적으로 분산된 배포를 할 때 통신은 인터넷을 거치기에 로컬에 비해 느리고 신뢰성도 떨어진다. 
  - 데이터센터의 네트워크는 IP와 이더넷을 주로 기반으로 하며 높은 양단 대역폭(bisection bandwidth)을 제공하기 위해 클로스 토폴로지(Clos topology)로 연결돼 있다.

슈퍼 컴퓨터는 부분 장애가 전체장애가 되지만, 클라우딩 컴퓨팅ㅇ은 분산된 노드만 죽게 하여 전체 작업은 돌아가게 한다.



## 신뢰성 없는 네트워크

> 분산 시스템은 하드웨어를 공유하지 않는 **비공유**시스템이고 네트워크로 연결되어 있다.

인터넷과 데이터센터 네부 네트워크 대부분은 **비동기 패킷 네트워크(asynchronous packet network)**이다. 이는 언제든 잘못될 수 있다.

![](https://velog.velcdn.com/images/cksgodl/post/3b1fe167-7473-4bf9-9f10-5c59b04a35fd/image.png)

- 요청 후 응답을 받지 못했다면 (a) 요청이 손실됐는지, (b) 원격 노드가 다운됐는지, (c) 응답이 손실됐는지 구별할 수 없다.

이런 문제는 대부분 **타임 아웃**을 통해 관리한다. 

### 현실의 네트워크 결함

우리는 아직 신뢰성 있는 네트워크 환경을 만들지 못했다. 

스위치, 로드밸런서와 같은 네트워크 장비를 추가하는 것은 결함을 줄여주지 않는다. 

> 네트워크 분단
>
> 네트워크 결함으로 일부가 다른 쪽과 차단되는 것을 네트워크 분단(network partition)이나 네트워크 분리(netsplit)이나 네트워크 결함(network fault)라고 한다.

네트워크 결함은 언제든 일어날 수 있고 소프트웨어는 이를 견뎌내도록(tolerating)하도록 구성해야 한다. 

### 결함 감지

- 로드 밸런서는 죽은 노드로 요청을 그만 보내야 한다.
- 단일 리더 복제를 활용하는 경우 리더에 장애가 발생하면 리더를 교체해야 한다.

그 렇다면, 어떻게 노드에 결함이 있는지 확인을 할 수 있을까? 

- 노드가 실행 중인 장비에 연결할 수 있지만 목적지 포트에서 수신 대기하는 프로세스가 없다면 `OS`가 친절하게 `RST`나 `FIN` 패킷을 응답으로 보내 `TCP` 연결을 닫거나 거부한다. 
  - RST (Reset) : **"Reset"**을 의미하며, 비정상적인 연결 종료 또는 문제 해결에 사용
    - 연결이 예상치 못한 상태에 있거나 더 이상 유효하지 않음을 나타냄
  - FIN (Finish) : **"Finish"**를 의미하며, 정상적인 연결 종료를 나타냄
    - TCP 연결의 한쪽에서 데이터 송신이 종료되었음을 나타낸다.


- 노드 프로세스가 죽었지만 노드의 `OS`는 아직 실행중이라면 스크립트로 다른 노드에게 프로세스가 죽었다고 알려서 타임아웃을 기다리지 않고 역할을 넘겨받게 할 수 있다.(`HBase`가 이렇게한다.)
- 데이터센터 내 네트워크 스위치의 관리 인터페이스에 접근할 수 있으며 질의를 보내 `HW` 수준의 링크 장애를 감지할 수 있다. 
이 방법은 스위치에 대한 접근을 할 수 없는 상황에선 배제되는 선택지이다. 
- 접속하려는 IP 주소에 도달할 수 없다고 라우터가 확신하면 `ICMP Destination Unreachable` 패킷으로 응답할 수도 있다. 
라우터에 이러한 장애 감지 능력이 없을 경우 네트워크의 다른 참여자들과 동일한 제한이 적용된다.

### 타임아웃과 기약 없는 지연

타임아웃의 설정값은 답이 없다.

성급하게 노드가 죽었다고 선언하면 문제가 된다. 노드가 실제로는 살아 있고 동작을 진행중인데 다른 노드가 역할을 넘겨 받으면 그 동작을 두 번할지도 모른다. 또한 이런 이른판단은 부하를 늘려 연쇄 장애를 유발할 수 있다.

### 네트워크 혼잡과 큐 대기

네트워크 패킷 지연도 큐 대기 때문인 경우가 많다.

> 여러 장비가 같은 목적지로 네트워크 트래픽을 보내면 스위치 큐가 가득 찰 수 있다. 아래 사진은 모두 포트3으로 패킷을 보내려 한다. 

![](https://velog.velcdn.com/images/cksgodl/post/6afc901e-1675-4870-95a6-b16940fa2b1b/image.png)

여러 노드가 같은 목적지로 동시에 패킷을 보내려 할 경우 

1. 네트워크 스위치는 패킷을 큐에 넣고 한 번에 하나씩 네트워크 링크로 넘겨야 한다. 
2. 네트워크 혼잡(network congestion)이라면 패킷은 슬롯을 얻을 수 있을 때까지 기다려야 한다. 
3. 패킷이 목적지 장비에 도착했을 때 여유 CPU가 없다면, 여유가 생길 때까지 요청은 OS가 큐에 넣어둔다. 큐에서 대기하는 시간은 제각각 다를 수 있다. 
4. 가상 환경에서 실행되는 OS는 다른 가상 장비가 CPU 코어를 사용하는 동안 멈추는 경우가 흔하다. 
   - 이 시간 동안 가상 장비는 네트워크에서 어떤 데이터도 받아들일 수 없기에 가상 장비 모니터가 들어오는 데이터를 큐에 넣어서 버퍼링한다. 
5. TCP는 흐름 제어(flow control)를 수행한다. 
   - 혼잡 회피(congestion avoidance)나 배압(backpressure)이라고도 하는 흐름 제어는 노드가 네트워크 링크나 수신 노드에 과부하를 가하지 않도록 자신의 송신율을 제한하는 것이다. 
  데이터가 네트워크에 들어가기 전에 큐 대기를 할 수 있다는 것이다.
  
TCP는 타임아웃 안에 확인 응답을 받지 않으면 패킷이 손실됐다고 간주하고 손실된 패킷은 자동으로 재전송한다. 

> **TCP vs UDP**
>
> 인터넷 방송, 화상회의 등 지연시간에 민감한 서비스는 UDP를 활용한다. TCP는 신뢰성이 있는 서비스에 활용하여 이 둘은 신뢰성 <-> 지연변동성 사이의 트레이드 오프가 있다.

고정된 타임아웃을 설정하는 대신 시스템이 변동성있게 대처하도록 지터(`jitter`)를 측정하고 관찰된 응답 시간의 분포에 따라 타임아웃을 자동으로 조절할 수 있다. 예를 들어 파이 증가 장애 감지기(`Phi Accrual failure detector`)가 있다.

#### TCP의 Sliding Window 흐름제어

![](https://velog.velcdn.com/images/cksgodl/post/bc1005e6-ab6e-4ede-8222-b1694457a78f/image.png)

윈도우 크기만큼 패킷을 모두 전송하고, 그 패킷들의 ACK이 확인되는대로 해당 윈도우를 옆으로 슬라이딩하면서 그 다음 패킷을 전송하는 방식으로 동작한다.

TCP/IP 를 사용하는 모든 호스트들은 송신 그리고 수신을 위한 2개의 Window 를 가지고 있다. 호스트들은 실제 데이터를 보내기 전에 3-Way Handshake 를 통해 연결 설정을 해줄 때 수신 호스트의 Receive Window 크기에 자신의 Send Window 크기를 맞춰 설정한다.


### 동기 네트워크 대 비동기 네트워크

전화의 경우는 동기식으로 작동한다. 전화를 하는 동안 두 유저만을 위한 회선이 만들어지며, 통화에 대해 보장된 양의 대역폭이 할당된다. 이런 방식은 네트워크 종단 지연 시간의 최대치가 정해져있기에 이를 **제한 있는 지연(bounded delay)**라고 한다.

#### 네트워크 지연을 예측할 수 없을까?

TCP패킷은 각 네트워크 대역폭을 기회주의적으로 사용한다. 가벼운 트래픽이라면 TCP는 가능한 먼저 전송하고자 할 것 이다.

이런 패킷교환을 사용하는이유로써 **순간적으로 몰리는 트래픽(bursty traffic)**을 들 수 있다. 웹 페이지 요청, 이메일 전송, 파일 전송은 특별한 대역폭 요구사항이 없으며, 가능하면 빨리 전송되기를 바랄 뿐이다.

> 인터넷은 대역폭을 **동적으로** 공유한다. 스위치는 모든 대역폭을 활용하기 위해 최선을 다한다. (따라서 큐 대기가 생긴다.) 이러한 현상은 CPU 코어와 쓰레드 사이에도 동일하게 일어난다. 

## 신뢰성 없는 시계

시계와 시간은 중요하다. 어플리케이션은 다음과 같은 질문에 대답하기 위해 다양한 방식으로 시계에 의존한다.

1. 요청이 타임아웃 되었나?
2. 99분의 응답 시간은 어떻게 되나?
3. 지난 5분당 평균 초당 몇 개의 질의를 했나?
4. 사용자가 우리 사이트에 시간을 얼마나 썼나?
5. 이 기사가 언제 게시됐나?
6. 며칠 몇 시에 미리 이메일을 보내야하나?
7. 캐시 만료시간

![](https://velog.velcdn.com/images/cksgodl/post/2e37cf8d-ff15-4865-91ae-86e1d61725c8/image.png)

- 결정 진동자(quartz crystal oscillator)

![](https://velog.velcdn.com/images/cksgodl/post/e4135b63-6d9c-4306-b156-c81050e5d391/image.png)

- 원자 시계

분산 시스템에서 시간은 다르므로 이를 다루기 까다롭다. 개별 장비는 개인 시계를 가지고 있다. 이런 시간들을 동기화 하는 것이 네트워크 시간 프로토콜(`Network Time Protocol`, NTP)로 서버 그룹에서 보고한 시간에 따라 컴퓨터 시간을 조정한다. 

### 단조 시계 대 일 기준 시계

현대 컴퓨터는 최소 두 가지 시계를 가지고 있다. 일 기준 시계(`time-of-day clock`)과 단조 시계(`monotonic clock`)이다.

#### 일 기준 시계

일 기준 시계는 벽시계 시간(`wall-clock time`)이라고도 한다. 자바의 `System.currentTImeMillis()`는 **에포크(epoch)**이래로 흐른 밀리초를 반환한다. 윤초는 세지 않으며 에포크는 UTC 1970년 1월 1일 자정을 가리킨다.

> 유닉스 설계와 초창기 컴퓨터의 기원
>
> 에포크 시간은 유닉스 운영 체제가 만들어질 때 도입되었다.
1969년에 유닉스 개발이 시작되었고, 당시 표준적인 날짜/시간 표현 방식이 없었기 때문에 유닉스 설계자들은 단순하고 일정한 기준점을 필요로 했다.
따라서 1970년 1월 1일 00:00:00 UTC가 이 기준점으로 선택되었다.

일 기준 시계는 `NTP`로 동기화 되며, 이는 일반적으로 이상한점이 많다. 로컬 머신이 너무 앞서면 시간이 과거로 돌아가며, 윤초를 무시한다.

따라서 이는 매우 거친 해상도를 가진다. 오래된 윈도우 시스템에서는 10밀리초 단위로 흐른다.

#### 단조 시계

단조 시계는 타임아웃이나 서비스 응답 시간 같은 지속시간을 재는 데 적합하다. 자바의 `System.nanoTime()`이 있다. _단조 시계란 이름은 항상 앞으로 흐른다는 사실에서 나왔다._

이는 CPU의 타이머에 의존하며 `NTP`는 컴퓨터가 서버보다 빠르면 단조시계의 진도수를 조정한다. 기본적으로 `0.05%`까지 올리거나 내릴 수 있지만, 시계를 앞으로 돌릴 수는 없다. 

이는 분산시스템에서 경과 시간을 재는 데 단조 시계를 쓰는 것은 일반적으로 괜찮다. 다른 노드의 시계 사이에 동기화가 돼야 한다는 가정이 없고 측정이 약간 부정확해도 민감하지 않기 때문이다.

### 시계 동기화와 정확도

_하드웨어 시계와 NTP는 그냥 짐승이다._ 왜 그런지 알아보자.

- 컴퓨터의 수정 시계는 정확하지 않다. **드리프트(drift)** 현상이 생긴다.(더 빠르거나 느리게 실행) 하루동안 약 17초의 드리프트가 생긴다.
- NTP 서버와 너무 많은 차이가 나면 동기화가 거부되거나 로컬 식가 리셋된다.
- NTP 서버와 연결이 방화벽으로 막히면 잘못된 시간으로 그냥 사는거다.
- NTP 동기화는 잘해야 네트워크 지연만큼만 좋을 수 있다. 네트워크 지연이 급증하면 이는 소용이 없다.
- NTP 서버들은 이상이 있거나 설정이 잘못돼어 이상한 시간을 보고할 수 있다.
- 윤초가 발생하면 1분의 길이가 59초, 61초가 되어 시스템을 망칠 수 있다. 
- 가상 장비에서 하드웨어 시계는 가상화돼서 정확한 시간을 요구하는 어플리케이션에는 추가적인 어려움이 생긴다.
- 모바일, 임베디드 하드웨어 시간은 전혀 믿을 수 없다. (동물의숲에서 닌텐도 시간 돌려서 이자먹기)

![](https://velog.velcdn.com/images/cksgodl/post/a1056ac1-f6c1-47d4-b391-a956596882a6/image.png)

### 동기화된 시계에 의존하기

견고한 소프트웨어는 잘못된 시간에도 대비해야 한다.

문제 중 하나는 시계가 잘못된다는 것을 눈치채기 어렵다. 수정 시계에 결함이 있거나 `NTP` 클라이언트가 잘못 설정됐다면 시계는 점점 멀어져갈 것이다. 즉 모든 장비 사이의 시계 차이를 모니터링해야 한다. 너무 차이나는 노드는 그냥 죽이고, 클러스터에서 제거해야 한다.

### 이벤트 순서화용 타임스탬프

분산 데이터베이스에서 시계가 다르면 누가 쓴게 더 최근 것이 될까?

![](https://velog.velcdn.com/images/cksgodl/post/5189178e-ef12-4c40-a02d-b3e62d172d9c/image.png)

- B는 A보다 인과성 측면에서 나중에 쓰지만 B가 쓸 때 사용하는 타임스탬프가 더 이르다. 따라서 B의 증가 연산은 손실된다.


이러한 LWW(Last Write Win)전략은 다중 리더 복제와 다양한 리더 기반 데이터베이스에서 널리 사용된다. 

> "최근"값을 유지하고 다른 것들을 버림으로써 충돌을 해소하고 싶은 유혹이 들더라도 "최근"의 정의는 로컬 일 기준 시계에 의존한다.

### 시계 읽기는 신뢰 구간이 있다.

로컬 네트워크 시계는 `NTP` 서버와 매분 동기화하더라도 언제라도 에러가 발생할 수 있다. 

대부분의 시스템은 이러한 에러를 노출하지 않는다. 예를 들어 `clock_gettime()`을 호출할 때 반환값은 해당 타임스탬프의 신뢰 구간이 5밀리초인지 5년인지 모른다.

스패너에 있는 `구글 트루타임 API`은 로컬 시계의 신뢰 구간을 명시적으로 보고한다. 이 `API`에 현재 시간을 요청하면 가능한 타임스탬프 범위 [`earliest, latest`]를 받는다.

TrueTime API에서 시각 정보는 GPS와 원자 시계로부터 얻는다. 서로 다른 시각 정보를 얻어오도록 하는 이유는 어느 한 쪽에 장애가 발생해 시각 정보를 얻어 올 수 없는 경우가 발생할 수 있기 때문이다. GPS를 이용한 시각 정보 얻기는 안테나 또는 수신기의 고장, 주변 전파의 간섭 등의 원인으로 실패할 수 있다. 원자 시계를 이용해 얻는 시간은 주파수 오류로 인한 오차가 발생한 것 일 수도 있다.

> [글로벌 분산 데이터베이스 Spanner - D2](https://d2.naver.com/helloworld/216593)
>
> `TrueTime API`에서 시각 정보는 `GPS`와 원자 시계로부터 얻는다. 서로 다른 시각 정보를 얻어오도록 하는 이유는 어느 한 쪽에 장애가 발생해 시각 정보를 얻어 올 수 없는 경우가 발생할 수 있기 때문이다. `GPS`를 이용한 시각 정보 얻기는 안테나 또는 수신기의 고장, 주변 전파의 간섭 등의 원인으로 실패할 수 있다. 
>
> TrueTime은 각 데이터센터 내에 여러 대의 타임 마스터(time master) 장비들로 구성되어 있는데, 대부분의 마스터는 각각 개별적인 안테나를 장착한 GPS 수신기를 가지고 있다. 모든 마스터는 주기적으로 시각 정보를 서로 비교해 가며 상태를 확인한다. 이 과정에서 각 마스터는 자신이 가진 시계의 오차를 확인하여 동기화하는 작업을 수행한다.

### 전역 스냅숏용 동기화된 시계

가장 흔한 스냅숏 격리 구현은 단조로 증가하는 트랜잭션ID를 활용한다. 분산 데이터 환경에서는 단조 증가 트랜잭션 ID를 생성하기는 어렵고, 트랜잭션 ID는 일관성을 지니지 못한다.

따라서 잘 동기화된 시계의 타임스탬프를 트랜잭션 ID로 활용한다. 구글의 스패너에서는 `True Time API`를 활용해 시계 신뢰구간을 구하고 이들이 겹치지 않는다면 순서를 확신할 수 있다.

![](https://velog.velcdn.com/images/cksgodl/post/d7ab9701-e16e-4a04-acaf-7202aeae1d7b/image.png)

### 프로세스 중단

![](https://velog.velcdn.com/images/cksgodl/post/d501575d-d897-4378-9549-87c7b6bb7320/image.png)

분산 환경에서 리더가 어떻게 살아있는지 알 수 있을까?

한가지 선택은 리더가 다른 노드들로부터 임차권(`lease`)를 얻는 것이다. 이는 타임아웃이 있는 잠금과 비슷하다. 

```java
while (true) {
	request = getIncomingRequest();

	//항상 임차권이 최소 10초는 남아있게 보장한다.
	if(lease.expiryTimeMillis - System.currentTimeMillis() < 10000) {
		lease = lease.renew();
	}

	if(lease.isValid()) {
		process(request);
	}

```

위의 코드는 동기화된 시계에 의존한다. 즉 로컬시계와 다른 시스템의 시계가 몇 초 이상 차이가 난다면 이 코드는 제대로 작동하지 않는다.

또한 `lease.isValid()` 이전에 STW로 인해 15초 이상 멈춘다고 가정해보자. 실행 중인 쓰레드를 어떤 시점에 선점(preempt)하고 시간이 지난후 재개할 수 있다. 선점된 스레드는 이를 알아채지 못한다. 

분산 시스템에선 공유 메모리가 없고 신뢰성 없는 네트워크를 통해 메시지를 보낼 수만 있다. 따라서 분산 시스템의 노드는 이와 동일하게 언제든 상당한 시간 동안 멈출 수 있다고 가정해야 한다. 

### 응답 시간 보장

프로세스의 중단의 원인은 제거할 수 있다.

비행기, 자동차같은 소프트웨어의 경우 **데드라인**이 명시되고, 이를 지키지 못하면 큰 장애가 발생할 수 있다. 이를 **엄격한 실시간 시스템(hard real-time)**이라고 한다.

> **실시간은 정말 실시간인가?**
임베디드 시스템에서 실시간은 시스템이 명시된 타이밍 보장을 모든 상황에서 만족하도록 신중하게 설계되고 테스트됐다는 뜻이다.
>
>웹에서의 실시간은 서버가 클라이언트에게 데이터를 푸시하고 엄격한 응답 시간 제약 없이 스트림 처리하는 것을 나타낸다.

자동차 사고가 났을 때 `STW`로 인해 에어백이 늦게 방출되면 큰일난다. 따라서 프로세스가 명시된 간격의 CPU 시간을 할당받을 수 있게 보장하는 스케줄링해주는 **시릿간 운영체제(real-teim operating system, RTOS)**가 필요하다.

이러한 운영체제는 응답하는 것을 우선시함으로 처리량이 더 낮을수도 있다.


### 가비지 컬렉션의 영향을 제한하기

실시간 처리를 위해 가비지 컬렉션 영향을 줄여야한다.

이를 위한 아이디어중 하나로 GC 중단을 노드가 잠시 계획적으로 중단되는 것으로 간주하고 노드가 가비지 컬렉션을 하는 동안 클라이언트로부터의 요청을 다른 노드들이 처리하게 하는 것이다. 이를 통해 p999 성능을 높일 수 있다.

다른 아이디어로 수명이 짧은 객체는 가비지 컬렉터를 사용하고, 큰 객체는 주기적으로 프로세스를 재시작하는 것이다. (롤링 배포 하듯이) 이러한 조치는 STW를 완전히 막을 수는 없지만 어플리케이션에 미치는 영향을 줄일 수 있다.

## 지식, 진실, 그리고 거짓말

분산 시스템은 공유 메모리가 없으며 네트워크는 신뢰할 수 없고, 시계또한 믿을 수 없고, GC또한 믿을 수 없다.

네트워크 상에 있는 그 모든정보를 믿을 수 없다. 하지만 우리는 시스템모델에 대한 가정을 명시하고 이러한 가정을 만족한다는 가정하에 시스템을 설계한다. 

이후 내용은 몇가지 보장을 제공하는 알고리즘을 통해 신뢰성있는 분산시스템 환경을 만드는 것을 알아본다.

### 진실은 다수결로 결정된다.

위에서 언급한 비대칭적인 결함이 있는 네트워크를 생각해보자. 
노드가 메세지 수신은 가능하지만 송신이 모두 유실되거나 지연된다고 하면, 해당 노드는 내부적으로 잘 동작하더라도 다른 노드는 응답을 받지 못하기 때문에 해당 노드가 죽었다고 선언할 수 있다. 
그럼 해당 노드는 살아있지만 죽은 노드 취급을 받게 될 것이다.

GC의 stop-the-world 가비지 컬렉션 중단이 분 단위로 오래걸린다고 가정하면, 중단된 시간동안 요청도, 응답도 진행되지 않기 때문에 다른 노드들은 마찬가지로 해당 노드가 죽었다고 판단할 수 있다. 

이러한 여러 상황의 공통점은 노드가 상황에 대한 자신의 판단을 반드시 믿을 수 있지 않다는 것이다. 분산 시스템은 어느 한 노드에만 의존할 수가 없다. 언제든 노드에 장애가 발생하고 잠재적으로 시스템이 멈추거나 복구조차 불가능할 수 있기 때문이다.

여러 분산 알고리즘은 **정족수** 및 투표에 의존한다. 이에대한 자세한 내용은 추후 장에서 설명한다.

### 리더와 잠금

분산 시스템은 하나의 리더만 필요하다. 하지만, 한 리더가 죽어서 투표에 밀려났지만 다시 살아날 수 있다. 

![](https://velog.velcdn.com/images/cksgodl/post/8fcdc766-183f-48f9-9e5d-9d128b0d3026/image.png)

- 분산 잠금의 잘못된 구현: 클라이언트 1은 임차권이 만료됐지만 여전히 유효하다고 생각해 저장소의 파일을 오염시킨다. 

위 그림은 방금 얘기한 문제를 다루는데, 클라이언트1이 가비지 컬렉션을 하느라 멈춘 시간동안 임차권이 만료되어 클라이언트2가 임차권을 획득하여 작업을 했는데, 클라이언트가 가비지 컬렉션 이후 저장소에 쓰기 작업을 수행하게 되면, 데이터 오염이 발생한다. 

### 펜싱 토큰

![](https://velog.velcdn.com/images/cksgodl/post/2cf5bb9f-ec91-4f8e-8f90-c79c794c7782/image.png)

따라서 부활한 (전)리더가 시스템을 방해할 수 없도록 보장해야 한다. 이를 구현하기 위한 단순하 기법으로 **펜싱(fencing)**기법이 있다.

![](https://velog.velcdn.com/images/cksgodl/post/c682db6b-66c2-4594-b83b-63a30e08a22b/image.png)

- 펜싱 토큰이 증가하는 순서에 맞는 쓰기만 허용함으로써 저장소에 대한 접근을 안전하게 만든다.

펜싱 토큰은 잠금이 승인될 때마다 증가하는 숫자로 구성한다. 또한 클라이언트가 쓰기 요청을 저장소 서비스로 보낼 때마다 자신의 현재 펜싱 토큰을 포함하도록 요구할 수 있다. 

### 비잔틴 결함

펜싱 토큰은 (전)리더의 횡포를 막을 수 있다. 그러나 노드가 가짜 펜싱 토큰을 만들어내면 시스템은 망가진다.

지금까지 노드는 모두 정직하다고 가정했다. 하지만, 노드가 "거짓말"을 할 수도 있다. 예를 들어 어떤 노드가 실제로는 받지 않은 특정 메시지를 받았다고 주장할 수 있다. 이런 동작을 **비잔틴 결함(Byzantine fault)**라고 하며 신뢰할 수 없는 환경에서 합의에 도달하는 문제를 **비잔틴 장군 문제(Byzantine Generals Problem)**이라고 한다.

![](https://velog.velcdn.com/images/cksgodl/post/98c12595-e18e-4732-afd7-0ae7f508c8f5/image.png)

일부 노드가 오작동하고 프로토콜을 준수하지 않거나 공격자가 네트워크를 방해하더라도 시스템이 올바르게 작동하면 이 시스템은 **비잔틴 내결함성을 지닌다(`Byzantine fault-tolerant`)**라고 한다.

보통 우리가 접하는 데이터센터나 시스템은 이러한 비잔틴 결함을 대비할필요는 없다. 이는 중앙 권한이 없는 피어투피어 네트워크에 더 적합하다.

### 약한 형태의 거짓말

노드들이 일반적으로 정직하다고 가정하지만, 약한 형태의 "거짓말"(소프트웨어 버그, 잘못된 설정)으로 부터 보호하는 것은 필요하다. 

### 시스템 모델과 현실

분산 시스템을 설계하기 위한 많은 알고리즘이 설계되고 다양한 시스템 모델이 정형화되고 있다.

#### 타이밍 가정

타이밍 가정에 대해서는 세 가지 시스템 모델이 흔하게 사용된다.

* 동기식 모델
  - 네트워크 지연, 프로세스 중단, 시계 오차에 모두 제한이 있다고 가정한다. 
  - 사실, 동기식 모델은 기약 없는 지연과 중단이 발생하는 대부분의 현실 시스템에서 현실적인 모델이 아니다. 

- 부분 동기식 모델
  - 대부분의 시간에는 동기식 시스템처럼 동작하지만 때때로 네트워크 지연, 프로세스 중단, 시계 드리프트의 한계치를 초과한다는 뜻이다. 많은 시스템에서 현실적인 모델로 보통은 잘 동작하지만 가끔씩 타이밍 가정이 조각 날지도 모른다는 사실을 고려해야 한다. 

- 비동기식 모델
  - 이 모델에서 알고리즘은 타이밍에 대한 어떠한 가정도 할 수 없다. 
  - 심지어 시계가 없을 수도 있다. (타임아웃을 쓸 수 없다는 의미기도 하다.)


#### 노드 장애 모델

이러한 타이밍 문제 외에 노드 장애도 고려해야 한다. 가장 널리 쓰이는 노드용 시스템 모델은 다음과 같다. 
   
* 죽으면 중단하는 (crash-stop) 결함
  - 알고리즘은 노드에 장애가 나는 방식이 죽는 것 뿐이라고 가정한다. 
  - 노드가 응답을 멈추면 그 이후로 그 노드는 영원히 사용할 수 없다는 뜻이다. 

- 죽으면 복구하는(crash-recovery) 결함
  - 노드가 어느 순간 죽을 수 있지만, 시간이 흐르면 다시 응답하기 시작할 것이라고 가정한다. 죽으면 복구하는 모델에서 노드는 메모리에 있는 상태는 손실되지만 죽어도 데이터는 남아 있는 안정된 저장소가 있다고 가정한다. 
- 비잔틴(임의적인) 결함
  - 노드는 다른 노드를 속이거나 기만하는 것을 포함해 전적으로 무슨 일이든 할 수 있다. 
   
### 안전성과 활동성

상황을 분명히 하기 위해 두 가지 다른 종류의 속성, **안전성(safety)**과 **활동성(liveness)**을 구별할 필요가 있다.

비공식적으로는 다음과 같이 정리된다.
- 안전성은 나쁜 일이 일어나지 않는다.
  - 안전성 속성이 위반되면 그 속성이 깨진 특정 시점을 가리킬 수 있다
- 활동성은 좋은 일은 결국 일어난다. 
  - 활동성 속성은 어떤 시점을 정하지 못할 수 있지만, 항상 미래에 그 속성을 만족시킬 수 있다는 희망이 있다. 

안전성과 활동성에 대한 실제 정의는 정확하고 수학적이다. 노드의 요청이 응답을 아직 받지 못했지만, 결국 응답을 받을 수 있다는 희망이 안전성과 활동성 속성을 구별하면 시스템 모델을 다루는데도 도움이 된다. 

분산 알고리즘은 시스템 모델의 모든 상황에서 안전성 속성이 항상 만족되기를 바라고,  (과정도 중요하다) 활동성 속성에 대해서는 경고를 하는게 허용된다. (결과가 중요하다)


## 정리

> 분산 시스템은 공유 메모리가 없으며 네트워크는 신뢰할 수 없고, 시계또한 믿을 수 없고, GC또한 믿을 수 없다.

따라서 **부분 실패(partial failure)** 가 생길 수 있고, 언제든 실패하거나 느려지거나 응답하지 않을 수 있다. 이를 대비한 내결함성을 갖추고자 노력한다. 하지만, 장애를 감지하는 것도 힘들고, 감지하고 이를 견딜 수 있게 만드는 것도 힘들다. 

이번 장에서는 네트워크, 시계, 프로세스가 신뢰성이 없는게 불가피하다는 것을 알아보았다. 다음 장에서는 이런 문제를 대처하도록 설계된 알고리즘을 살펴본다.




