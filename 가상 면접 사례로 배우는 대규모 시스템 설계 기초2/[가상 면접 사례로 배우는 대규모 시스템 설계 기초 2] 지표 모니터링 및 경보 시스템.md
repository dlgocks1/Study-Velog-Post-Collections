## 설계안

지표 및 모니터링 경보 시스템은 다음과 같은 컴포넌트를 활용한다.

- 데이터 수집 (data collection) : 여러 출처로부터 지표 데이터 수집
- 데이터 전송 (data transmission) : 지표 데이터를 지표 모니터링 시스템으로 전송
- 데이터 저장소 (data storage) : 전송되어 오는 데이터를 정리하고 저장
- 경보 (alerting) : 밀려오는 데이터를 분석하고, 이상 징후를 감지하고, 경보를 발생시킴 to 다양한 통신 채널
- 시각화 (visualization) : 데이터를 차트, 그래프 등으로 제공 for 패턴, 추이, 문제점을 쉽게 파악하기 위함

### 데이터 모델

지표 데이터는 통상 시계열(time series) 데이터 형태로 기록한다 → 값 집합에 따임스탬프가 붙은 형태

> 각 시계열데이터 == 고유명 + label
>
>|이름|	자료형|
|-----|---|
|지표 이름|	문자열|
|태그/레이블 집합|	<키:값> 쌍의 list|
|지표 값 및 그 타임스탬프의 배열|	<값, 타임스탬프> 쌍의 array|


- 사례 1

서버 인스턴스 i631의 20:00 시점의 CPU 부하를 알고 싶다.

```
metric_name	cpu.load
labels	host:i1631, env:prod
timestamp	1613707265
value	0.29
```

- 사례2

지난 10분간 us-west 지역에 위치한 모든 웹 서버의 CPU 부하 평균값은 얼마인가?

지표 이름이 CPU.load이고 레이블에 포함된 지역 이름이 us-west인 데이터 저장소에서 가져온다.

```
CPU.load host=webserver-01,region=us-west 1613707265 50
CPU.load host=webserver-01,region=us-west 1613707265 70
****CPU.load host=webserver-02,region=us-west 1613707265 32
...
****CPU.load host=webserver-02,region=us-west 1613707265 54
****CPU.load host=webserver-01,region=us-west 1613707265 83
```

**각 행의 데이터 형식은 행 프로토콜을 따르고, 프로메테우스가 이형식을 활용한다.**

### 데이터 접근 패턴

![](https://velog.velcdn.com/images/cksgodl/post/e5cf2ab8-808a-4870-bc57-8a0839aed1b0/image.png)

- x축 : 시간
- y축 : 하나의 시계열 데이터 (metric name+label로 식별되는 값)

데이터가 많을수록 트래픽 빈도가 매우 높았음을 의미한다.

__해당 시스템은 쓰기비율이 압도적이다.__

### 데이터 저장소 시스템

> __모니터링 시스템 구축을 위한 저장소를 직접 설계하거나, MySQL 등의 범용 저장소를 사용하는 선택지는 배제한다.__
>
> MySQL, NoSQL 등 범용 저장소는 전문사 수준의 튜닝이 필요하고, 타임스템프, 레이블 별 인덱스, 쓰기연산에 최적화 필요
>
> (_특히, 관계형 데이터베이스(e.g. MySQL)는 시계열 데이터 대상의 연산에 최적화 X (많은 양의 쓰기 연산이 지속적으로 발생하는 환경에 그리 좋은 성능을 보이진 않음)
NoSQL(e.g. Cassandra, Bigtable)은 시계열 데이터 처리에 사용될 수는 있으나, 확장이 용이한 스키마 설계를 위해 해박한 내부 구조에 대한 배경지식이 필요함_)

시장에 있는 다양한 시계열 데이터에 최적화된 저장소 시스템을 활용한다.

- InfluxDB
- Prometheus

----

> #### 시계열 데이터베이스(`Prometheus`)의 특징
>
- 다량의 시계열 데이터를 저장
- 빠른 실시간 분석 지원
   - 최근 수분 ~ 2시간까지의 데이터는 메모리에서 바로 읽음
   - WAL 구조, 타임스탬프 기반 순차적 읽기
   - Label에 인덱스가 걸려 있음
   - Prometheus의 PromQL은 자체 쿼리 최적화 제공
- **메모리 캐시와 디스크 저장소를 함께 사용**
>
```
1. 메트릭 수신
    ↓
2. Head Block (메모리)
    ↓      ← 메모리 최신 데이터 저장 (블록)
3. WAL (Write Ahead Log) ← 디스크
    ↓
4. Block 생성 (디스크에 Snapshot) ← n시간 주기
```
- 영속성 요건과 높은 성능 요구사항을 잘 만족함
   - 메모리 및 WAL구조 디스크를 활용
- 막대한 양의 시계열 데이터를 레이블(or 태그) 기준으로 집계하고 분석하는 기능을 제공
  - InfluxDB - **레이블별 인덱스 구축**
- 이와 동시에 DB 과부하가 발생하지 않도록 각 레이블이 가질 수 있는 값의 가짓수(cardinality)가 낮아야 한다
  - 카디널리티는 데이터의 해상도 및 용량적인 측면에서도 영향이 있다.


### 계략적 설계안

![](https://velog.velcdn.com/images/cksgodl/post/b96e4c28-bbc1-4a28-b94b-99b2015881bd/image.png)

| 구성 요소     | 설명                                                                 |
|--------------|----------------------------------------------------------------------|
| 지표 출처     | 지표 데이터가 만들어지는 곳 (애플리케이션 서버, SQL 데이터베이스, 메시지 큐 등) |
| 지표 수집기   | 지표 데이터를 수집하고 시계열 데이터를 기록하는 역할                       |
| 시계열 DB     | 지표 데이터를 시계열 데이터 형태로 보관하는 저장소                           |
| 질의 서비스   | 시계열 데이터베이스에 보관된 데이터를 질의하고 가져오는 과정을 돕는 서비스       |
| 경보 시스템   | 경보를 받아야 하는 다양한 대상으로 경보 알림을 전송하는 역할을 하는 시스템         |
| 시각화 시스템 | 지표를 다양한 형태의 그래프/차트로 시각화 하는 기능 제공                        |

## 동작 과정

### 지표 수집

지표는 소실되어도 되고, ack등의 확인은 필요 없다.

![](https://velog.velcdn.com/images/cksgodl/post/612e6ca9-cf8d-45c4-bf57-e11ea1909ee1/image.png)

#### 풀 모델

![](https://velog.velcdn.com/images/cksgodl/post/5e63f175-b110-4fd1-870c-7c6c6324f25e/image.png)

**대표적 사례 : Prometheus**

실행 중인 애플리케이션에서 주기적으로 지표 데이터를 가져오는 지표 수집기가 흐름의 중심

- 지표 수집기는 데이터를 가져올 서비스 목록을 알고 있다.
- 서버 안에 모든 서비스 엔드포인트와 DNS/IP 정보를 담은 파일 두기
- 서비스 탐색 기술(e.g. etcd, Apache Zookeeper, `k8s api`)을 활용해 수시로 변경되는 대규모 운영 환경에도 적용 가능
   - 한 대의 서버로는 다량의 데이터를 수집하기 어려우므로, 지표 수집기 서버 풀을 만들어야 감당 가능 → 안정 해시 링을 이용해 메커니즘 구현
- 사전에 합의된 HTTP 엔드포인트에서 지표 데이터를 가져온다 
- 서비스 엔드포인트 목록의 변화를 통지 받기 위한 변경 이벤트 알림 콜백을 서비스 탐색 컴포넌트에 등록할 수 있다

#### push 모델

![](https://velog.velcdn.com/images/cksgodl/post/d956b70e-aab1-4667-a493-c14f88607027/image.png)

**Amazon CloudWatch, Graphite**

지표 출처에 해당하는 서버(웹 서버, 데이터베이스 서버 등)가 직접 지표를 수집기에 전송하는 모델

- 모니터링 대상 서버에 수집 에이전트라는 소프트웨어를 설치한다
- 수집 에이전트의 역할 
  - 해당 장비에서 실행되는 서비스가 생산하는 지표 데이터를 받아서 모아둔 후, 주기적으로 수집기에 전달 (간단한 지표는 직접 집계 가능)
- 데이터 집계는 수집기에 보내는 데이터 양을 줄이는 효과적인 방법이다
- 지표 수집기가 지표 데이터를 제때 처리하지 못하는 상황을 방지하려면, 지표 수집기 클러스터 자체가 auto scaling이 가능하게 하고 그 앞에 로드밸런서를 두면 된다.

#### 장단점 비교

| 항목                        | 풀 모델                                                                 | 푸시 모델                                                                                     |
|---------------------------|------------------------------------------------------------------------|----------------------------------------------------------------------------------------------|
| 손쉬운 디버깅                | 특정 엔드포인트를 두어 언제든 지표 데이터 조회 가능 → **풀 모델이 더 낫다**                    | -                                                                                            |
| 상태 진단 (health check)   | 풀 요청에 응답하지 않으면 장애로 인지 가능 → **풀 모델이 더 쉽다**                              | **네트워크 장애와 서버 장애 중 어떤 게 원인인지 구분 어려움**                                       |
| 생존 기간이 짧은 프로세스       | -                                                                      | 수집기가 데이터를 끌어가기 전에 종료되어도 push gateway 사용으로 해결 가능 → **푸시 모델이 유리**  |
| 방화벽/복잡한 네트워크 구성     | 동일한 엔드포인트 구성 가능, 하지만 멀티 데이터센터 환경에선 설계가 복잡함                          | 수집기가 로드밸런서 뒤에 있으면 어디서든 수집 가능 → **푸시 모델이 더 낫다**                     |
| 성능                        | TCP 사용 → 오버헤드가 낮고 안정적                                              | UDP 사용 가능 → 지표 전송 지연 낮음                                                       |
| 데이터 신빙성                | 애플리케이션 서버가 명확 → 신뢰 가능                                          | 아무나 수집기에 보내기 쉬움 → 허용 목록 설정이나 인증 등 보완 필요                                |

### 지표 전송 파이프라인 규모 확장

![](https://velog.velcdn.com/images/cksgodl/post/9cc4f2b6-33d0-4771-937c-53f0667c0049/image.png)

> **규모확장을 위해 지표 데이터를 카프카와 같은 큐 시스템에 전송할 수 있다.** 
이는 아래와 같은 장점이 있다.
>
- 결합도를 낮춘다
- 데이터베이스에 장애가 생겨도 데이터는 소실되지 않는다 (카프카에 보관해두면 됨)

#### [카프카를 통한 규모 확장]

- 대역폭 요구사항에 따라 파티션이 수를 설정한다
- 지표 이름에 따라 어떤 지표를 어느 파티션에 배치할지 결정하면 소비자는 지표 이름에 따라 데이터를 집계할 수 있다
- 태그/레이블에 따라 지표 데이터를 더욱 세분화한 파티션으로 나눈다

### 질의 서비스

![](https://velog.velcdn.com/images/cksgodl/post/e364fe7a-c35c-4e20-b9bd-47245d657007/image.png)

질의 서버 클러스터 형태로, 시각화 또는 경보 시스템에서 접수된 요청을 시계열 데이터베이스를 통해 처리하는 역할을 담당한다.

시계열 DB에 질의 처리 전담 서비스를 클라이언트에 두면 결합도를 낮출 수 있다. 추가적으로 질의 결과를 저장할 캐시 서버를 도입하여 데이터베이스에 대한 질의 서비스 성능을 높일 수 있다. -> 그라파나에서 UI 캐싱은 제공한다.

프로메테우스, InfluxDB(→ Flux)에서는 SQL이 아닌 독자 질의어를 제공한다 (for 시계열 데이터 질의에 최적화)


### 저장소 계층

#### 저장용량 최적화


1. 데이터 인코딩 및 압축

타임스탬프의 경우 중복된 숫자가 많음으로 이를 압축하여 저장한다. 예제로써는 **이중-델타 인코딩**이 있다.

2. 다운샘플링

데이터의 해상도를 낮춰 저장소 요구량을 줄이는 것이다.

- 7일 내 데이터 : 샘플링 적용
- 30일 이내 데이터 : 1분 해상도로 낮춰 보관
- 1년 이내 데이터 : 1시간 해상도로 낮춰서 보관한다.

> **드루이드의 다운샘플링**
>
> 드루이드의 경우는 데이터에 대한 리텐션을 지정하거나, 일자가 많이 지난 데이터를 컴팩션하여 해상도를 굵게 재조정하는 다운샘플링 작업을 활용할 수 있다. (`Granuality`)
>
> 추가적으로 **롤업** 기능을 제공한다.
> 롤업은 데이터 적재 시 동일한 타임스탬프 및 차원(디멘션) 값에 대해 미리 집계(Pre-aggregation)하여 하나의 행(row)으로 만드는 방식이다.
> ![](https://velog.velcdn.com/images/cksgodl/post/1914b0bb-12a4-4df6-9b66-f7c221f8268d/image.png)
>
> 즉 드루이드의 각 디멘션이 전부 다르면 롤업 효과가 줄기에 카디널리티를 줄이는 것이 중요하다.
>
> _유저의 행동 로그를 저장하는 경우 쿠키나, 유저 정보의 경우 모두 다른 차원을 가지기에 롤업을 위해서는 하이퍼로그로그 알고리즘을 활용하여 카디널리티를 추정하기도 한다._ [확률적 자료구조를 이용한 추정 - 유일한 원소 개수(Cardinality) 추정과 HyperLogLog](https://d2.naver.com/helloworld/711301)


3. Cold Storage

콜드 스토리지는 잘 사용되지 않는 비활성 상태 데이터를 보관하는 곳이다. 일반 저장소에 비해 현저히 적은 비용으로 활용가능하다.

> 콜드 스토리지 예제 (드루이드 기준)
>
> `Hot Storage`: 최근/자주 조회되는 데이터(예: 최근 1개월)는 빠른 디스크(SSD 등), 다수의 노드에 여러 복제본을 둬서 저지연 쿼리에 대응
>
> `Cold Storage`: 과거 데이터(예: 1개월 이전)는 느리거나 저렴한 저장소 또는 복제본 수가 적은 tier에 저장하거나, 아예 deep storage(S3, `HDFS` 등)만 남기고 데이터 노드(Historical)에서는 내려버려 비용을 절감


### 경보 시스템

#### 경보 시스템 - 만들 것인가 구매할 것인가
이미 상용품이 널리 쓰이고 있고, 실무에서 경보 시스템을 밑바닥부터 구현하겠다는 아이디어는 수용되기 어렵다.

1. 설정 파일을 가져와 캐시 서버에 보관한다 (경보 규칙(주로 *.yaml)은 디스크에 파일 상태로 보관)

```
- name: instance_down
rules:

# Alert for any instance that is unreachable for >5
- alert: instance_down
		expr: up == 0
		for: 5m
		labels:
		security: page
```
2. 경보 관리자는 경보 설정 내역을 캐시에서 가져온다
3. 설정된 규칙에 근거하여 경보 관리자는 지정된 시간마다 질의 서비스를 호출한다
3-1. 질의 결과가 설정된 threshold를 위반하면 경보 이벤트 생성
4. 경보 이벤트를 카프카에 전달한다
5. 경보 소비자는 카프카에서 경보 이벤트를 읽는다
6.경보 소비자는 카프카에서 읽은 경보 이벤트를 처리하여 이메일, 단문 메시지, PagerDuty, HTTP 서비스 엔드포인트 등의 다양한 채널로 알림을 전송한다

### 시각화 시스템

시각화 시스템은 데이터 계층 위에 만들어진다.

-> [권장] 상용품을 구입해서 쓰는 것이 바람직하다 (ex. `Grafana`)

## 마무리

![](https://velog.velcdn.com/images/cksgodl/post/a5b55a07-ae24-493c-997d-b397cfc238e7/image.png)

- 지표 데이터 수집 모델 : 풀 모델 VS 푸시 모델
- 카프카를 활용한 규모 확장 방안
- 최적 시계열 데이터베이스의 선정
- 다운샘플링을 통한 데이터 크기 절감
- 경보/시각화 시스템 : 구현할 것인가 VS 구입할 것인가

![](https://velog.velcdn.com/images/cksgodl/post/8b6f94bc-f949-4707-90de-d6867cec079b/image.png)

## Ref

- https://github.com/SPRING-STUDY-2023/System-Design-Interview2/blob/main/yejun/5%EC%9E%A5.%20%EC%A7%80%ED%91%9C%20%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81%20%EB%B0%8F%20%EA%B2%BD%EB%B3%B4%20%EC%8B%9C%EC%8A%A4%ED%85%9C.md









