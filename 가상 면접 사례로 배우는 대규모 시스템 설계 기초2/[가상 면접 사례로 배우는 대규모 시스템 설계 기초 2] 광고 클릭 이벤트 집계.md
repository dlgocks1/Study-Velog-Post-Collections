# 대규모 광고 클릭 이벤트 집계 시스템 설계

> 디지털 광고 시장에서 RTB(Real Time Bidding)는 필수적인 프로세스다.
>
> 이는 즉 실시간 경매라 부른다. 이 경매 절차를 통해 광고가 나갈 지면을 거래한다.

광고 클릭, 노출에 따라 광고주가 내야 할 비용이 결정된다.

![](https://velog.velcdn.com/images/cksgodl/post/2b552941-2f33-42c5-819f-9b80283f66cc/image.png)

RTB는 속도가 중요 -> 1초 이내 모든 프로세스 이루어져야 함

CTR, CVR 등 광고 로그에 기반하여 성과를 측정한다.

- 관련 AdTech를 제공하는 기업

![](https://velog.velcdn.com/images/cksgodl/post/07529973-336b-40d2-ae81-28ae46583a70/image.png)


## 데이터 모델

![](https://velog.velcdn.com/images/cksgodl/post/b125b0ac-3c25-4a87-b63c-8212b72191fd/image.png)


- 로그 데이터를 그대로 저장하는 원시 데이터 DB
  - 쓰기에 최적화된 데이터베이스 사용: 쓰기 작업이 주를 이루기 때문에, 쓰기 작업에 유리한 데이터베이스인 **Cassandra나 InfluxDB**가 적합할 수 있다.
  - **AWS S3** 같은 blob storage에 데이터를 저장하는 방법도 효율적입니다. ORC, Parquet, AVRO 같은 형식으로 데이터를 저장하면, 데이터의 압축과 최적화가 가능해져 대규모 데이터를 효율적으로 관리할 수 있습니다.
- 가공한 집계 결과 데이터 DB
  - Aggregated data는 질의 성능을 고려하여, 읽기와 쓰기 성능이 균형 잡힌 데이터베이스에 저장하는 것이 중요. SQL 기반의 데이터베이스나 **NoSQL** 데이터베이스 중 적합한 솔루션을 선택할 수 있으며, 데이터의 사용 패턴에 따라 적합한 기술을 선택해야 한다.
  
원시 데이터만 저장하면
- 원본 데이터를 손실 없이 보관할 수 있다. 데이터 필터링 및 재계산을 할 수 있다.
- 데이터 용량이 막대하다. 따라서 조회 쿼리 성능도 낮아진다.

집계 데이터만 저장하면
- 데이터 압축을 통해 용량을 절감할 수 있다. 조회 쿼리 성능이 높아진다.
- 데이터가 손실될 수 있다. 원본 데이터가 아닌 한 번 압축/집계된 데이터이기 때문이다.

평소 대시보드에 노출할 데이터를 가져올 때에는 집계 결과 DB를 활용한다. `잘못된 데이터`임을 판단하기 위한 기준은 원시 데이터가 저장된 DB가 된다.

![](https://velog.velcdn.com/images/cksgodl/post/4e54093d-5140-4e24-b61b-dd2a85dc3713/image.png)

### 비동기 처리의 필요성

동기식 처리 시스템은 예기치 못한 트래픽 증가에 취약하여 전체 시스템의 장애로 이어질 수 있다. 이를 방지하기 위해, `Kafka`와 같은 메시지 큐를 도입하여 생산자와 소비자 간의 결합을 끊어 비동기 처리를 할 수 있다. 

### 집계 서비스의 설계

맵리듀스 프레임워크는 대규모 데이터를 처리하는데 적합한 방안 중 하나이다. **Hadoop**, Hive, Presto, Spark 같은 기술을 활용. 이들 기술은 각각의 특성과 장단점을 가지고 있으며, 사용 사례에 따라 적합한 기술을 선택할 수 있다.


### 맵 리듀스

> 저장된 원시 데이터를 집계하기 위해 맵 리듀스 방식을 활용할 수 있다. 하둡에서 널리 제공되는 프레임워크이며, 대용량 배치를 통해 데이터를 수집한다.

![](https://velog.velcdn.com/images/cksgodl/post/6d8bb541-8997-4155-850b-155c98b84179/image.png)


- 클릭 이벤트 수 집계: map node에서 `ad_id` 기준으로 이벤트를 분배하고, `reduce node`에서 최종적으로 집계.
- 데이터 필터링: 클릭 이벤트 데이터에 추가적인 차원(예: country)을 도입하여 필터링할 수 있다.

![](https://velog.velcdn.com/images/cksgodl/post/37f49936-c11e-4906-b5ef-6c7b690f55fe/image.png)

단, 맵리듀스 방식은 대규모 데이터를 분산 + 병렬 + 제대로 된 셔플 처리 할 때 효과가 있다. 싱글 스레드 환경에서는 맵리듀스를 써봤자 그냥 전통적인 방식으로 처리하는거랑 성능이 비슷하다고 한다.
  

### 집계된 데이터

![](https://velog.velcdn.com/images/cksgodl/post/c3943563-d3c3-457e-b728-4a8a1e8fad72/image.png)

미국 내 광고에 대해 집계뙨 클리굿만 표시 같은 데이터필터링을 위해 위와 같이 집계할 수 있다. 
이런 기법을 스타 스키마라고 부르며, 데이터 웨어하우스에서는 위와같이 널리 쓰인다.



### 드루이드의 실시간 Kakfa Ingestion과 Map Reduce 배치

![](https://velog.velcdn.com/images/cksgodl/post/db546208-6ae2-4fba-8e5b-8f5579f2e327/image.png)

> 참고)  MapReduce 프레임워크의 경우는 동기적으로 작동하기 때문에 실시간으로 쿼리가 불가능하다. 드루이드와 같은 OLAP데이터베이스에서 대안으로 Kafka 인제스쳔을 제공한다.

> 하둡의 `Map Reduce` 프레임워크와 동일하게 드루이드의 `Map Reduce` 방식을 통해 데이터를 `Aggregation`하는데 활용할 수 있다.
> Kafka를 통해 데이터를 활용할 수도, Hadoop을 통해 데이터를 불러올 수도 있다.

하둡에서 저장된 데이터를 SQL처럼 직접 쿼리하려면 Hive와 같은 별도 SQL 엔진을 설치해 조회해야 한다. Druid의 경우는 제공하는 가상 SQL 및 Druid Native Query를 통해 데이터를 조회할 수 있다.

- 처리 방식
  - **Kafka 인제스천**: 실시간(스트리밍) 방식으로 Kafka 토픽에서 데이터를 지속적으로 읽어들여 Druid에 바로 인덱싱 및 쿼리 가능한 데이터로 변환한다. 
  - **Hadoop 배치(MapReduce)**: 대량의 과거 데이터를 한 번에 수집(배치 방식)할 때 사용된다. YARN 위에서 MapReduce 작업을 수행하여 병렬로 데이터를 처리한 후 Druid로 적재한다.
- 목적 및 활용 시점
  - Kafka 인제스천: **실시간 분석**, 빠른 이벤트 반영, 스트림 데이터 즉시 쿼리 목적으로 활용. 실시간 모니터링, 대시보드 등 신속성이 요구되는 상황에 적합하다.
  - Hadoop 배치: 이력 데이터나 **대용량 데이터를 한 번에 처리하고 적재할 때 사용**. 과거 데이터 집계, 리포트 등 주기적으로 대량 데이터 적재가 필요한 환경에 적합.
- 성능 및 응답 속도
  - Kafka 인제스천: 인제스천 및 쿼리 응답이 빠르고, 데이터가 적재되자마자 바로 분석 가능하다.
  - Hadoop 배치(MapReduce): 적재에 시간이 오래 걸릴 수 있으나, 병렬 처리로 대규모 데이터 집계/분석에 유리하다. 쿼리 응답 속도는 Hadoop이 느리고, Druid에 적재된 이후 쿼리가 가능해진다.

### Druid 집계시의 Roll up에 관하여 

> Druid의 **롤업(Roll-up)**은 데이터를 수집(인제스트)할 때, 동일한 시간대와 차원값(Dimension)에 대한 측정값(Metric)을 미리 집계해서 저장하는 사전 집계(pre-aggregation) 방식이다.

롤업을 적용하면 여러 이벤트들을 지정한 시간 단위(timestamp granularity)와 동일한 차원값별로 그룹핑하여, row 수와 원본 데이터 저장 용량을 대폭 줄일 수 있다. 
(`rollup`을 실행할 시간 차원을 지정해야한다.)

예를 들어, 1분 단위 granularity로 롤업하면 같은 1분과 동일 차원값의 데이터는 합산해서 하나의 row로 저장된다.

![](https://velog.velcdn.com/images/cksgodl/post/c3943563-d3c3-457e-b728-4a8a1e8fad72/image.png)

- 장점과 트레이드오프
  - 장점: 저장 공간 효율화(수십~수백 배 축소 가능), 빠른 쿼리 속도, 집계 기반 분석에 최적.
  - 단점: 롤업된 granularity 아래의 개별 이벤트 쿼리는 불가능하며, 그룹 기준을 세분화할수록 집계 성능이 달라질 수 있다.

롤업을 비활성화하면 원본 이벤트 단위로 데이터가 저장되어, SQL 기반의 다른 데이터베이스처럼 단일 이벤트 조회가 가능하다.


설정 방식과 동작원리
rollup 옵션은 ingestion spec 설정에서 granularitySpec.rollup: true로 지정하며, 집계 단위는 queryGranularity에서 결정한다.

Druid는 streaming ingestion에서는 Best-effort rollup(완전한 집계는 아니나 최대한 그룹화), 배치 ingestion에서는 Perfect rollup(완전한 사전 집계) 방식으로 동작한다.

예시 및 적용
웹 서버 로그, 클릭스트림, 센서 데이터 등의 시계열 데이터에 활용도가 높다.

예를 들어, 1시간 단위 granularity의 롤업을 적용하면, 각 시간과 차원별로 발생 건수가 합산되어 가격, 카운트 등 metric만 쿼리가 가능하다.

Druid의 롤업은 실시간 분석 성능과 저장 효율을 높이기 위한 대표적인 기능으로, 대량의 이벤트성 데이터에 매우 유용하다.

